"""
æç¤ºè¯ç®¡ç†æ¨¡å— - Sight Server
é›†ä¸­ç®¡ç†æ‰€æœ‰Agentå’ŒLLMä½¿ç”¨çš„æç¤ºè¯æ¨¡æ¿

å¯å‘å¼è®¾è®¡ç†å¿µï¼šä»æŒ‡ä»¤å¼è½¬å‘å¯å‘å¼ï¼Œè°ƒåŠ¨LLMè‡ªèº«çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›
"""

from typing import Optional, Dict, Any, List
from enum import Enum
import logging

logger = logging.getLogger(__name__)


class PromptType(Enum):
    """æç¤ºè¯ç±»å‹æšä¸¾"""
    SCENIC_QUERY = "scenic_query"  # æ™¯åŒºæŸ¥è¯¢æç¤ºè¯
    SPATIAL_QUERY = "spatial_query"  # ç©ºé—´æŸ¥è¯¢æç¤ºè¯
    GENERAL_QUERY = "general_query"  # é€šç”¨æŸ¥è¯¢æç¤ºè¯
    SUMMARY_QUERY = "summary_query"  # âœ… æ–°å¢ï¼šç»Ÿè®¡æ±‡æ€»æŸ¥è¯¢æç¤ºè¯


class QueryIntentType(Enum):
    """æŸ¥è¯¢æ„å›¾ç±»å‹æšä¸¾"""
    QUERY = "query"      # æŸ¥è¯¢ç±»ï¼šè·å–å…·ä½“æ•°æ®
    SUMMARY = "summary"  # æ€»ç»“ç±»ï¼šç»Ÿè®¡æ±‡æ€»åˆ†æ


# ==================== æŸ¥è¯¢æ„å›¾åˆ†æå…³é”®è¯åº“ ====================

# ç©ºé—´æŸ¥è¯¢å…³é”®è¯ï¼ˆæ‰©å……ç‰ˆï¼‰
SPATIAL_KEYWORDS = [
    # å¼ºç©ºé—´å…³é”®è¯
    'è·ç¦»', 'é™„è¿‘', 'å‘¨å›´', 'èŒƒå›´å†…', 'æœ€è¿‘', 'å‘¨è¾¹', 'ä¸´è¿‘', 'é è¿‘', 'é‚»è¿‘',
    'è·¯å¾„', 'è·¯çº¿', 'é™„è¿‘çš„', 'å‘¨å›´çš„', 'æ—è¾¹', 'è¾¹ä¸Š',
    # PostGISç›¸å…³
    'ç›¸äº¤', 'åŒ…å«', 'åœ¨å†…', 'è¾¹ç•Œ', 'ç¼“å†²', 'ç¼“å†²åŒº',
    # è‹±æ–‡å…³é”®è¯
    'distance', 'near', 'nearby', 'around', 'within',
    'route', 'path', 'nearest', 'proximity', 'intersect',
    'contain', 'buffer', 'st_', 'dwithin', 'surrounding'
]

# æ€»ç»“/ç»Ÿè®¡ç±»æŸ¥è¯¢å…³é”®è¯ï¼ˆæ‰©å……ç‰ˆï¼‰
SUMMARY_KEYWORDS = [
    # å¼ºç»Ÿè®¡å…³é”®è¯
    'ç»Ÿè®¡', 'æ€»ç»“', 'æ±‡æ€»', 'è®¡æ•°', 'æ€»æ•°', 'æ€»è®¡', 'ä¸€å…±', 'æ€»å…±', 'å…±æœ‰', 'åˆè®¡',
    # æ•°é‡ç›¸å…³
    'å¤šå°‘', 'æ•°é‡', 'ä¸ªæ•°', 'æœ‰å‡ ä¸ª', 'æœ‰å¤šå°‘', 'å‡ ä¸ª',
    # èšåˆå‡½æ•°
    'åˆ†å¸ƒ', 'å¹³å‡', 'æœ€å¤š', 'æœ€å°‘', 'æ’å', 'åˆ†æ',
    'å æ¯”', 'ç™¾åˆ†æ¯”', 'æ¯”ä¾‹',
    # è‹±æ–‡å…³é”®è¯
    'count', 'sum', 'average', 'max', 'min', 'total',
    'statistics', 'summary', 'analyze', 'how many', 'percentage'
]


class PromptManager:
    """
    æç¤ºè¯ç®¡ç†å™¨

    åŠŸèƒ½:
    - é›†ä¸­ç®¡ç†æ‰€æœ‰æç¤ºè¯æ¨¡æ¿
    - æ”¯æŒåŠ¨æ€æç¤ºè¯ç”Ÿæˆ
    - æä¾›æç¤ºè¯è‡ªå®šä¹‰æ¥å£
    - æ¨¡æ¿å˜é‡æ›¿æ¢
    """

    # ==================== å¯å‘å¼æ™¯åŒºæŸ¥è¯¢æç¤ºè¯ ====================
    SCENIC_QUERY_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªç²¾é€šPostgreSQLå’ŒPostGISçš„ç©ºé—´æ•°æ®æŸ¥è¯¢ä¸“å®¶ï¼Œä¸“é—¨å¤„ç†å…¨å›½æ™¯åŒºæ—…æ¸¸æ•°æ®æŸ¥è¯¢ã€‚

## ğŸ¯ å¯å‘å¼æ€è€ƒæ¡†æ¶

**è¯·è¿ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œè‡ªä¸»åˆ†ææŸ¥è¯¢éœ€æ±‚å¹¶ç”Ÿæˆæœ€ä¼˜SQLï¼š**

### æ ¸å¿ƒæ€è€ƒåŸåˆ™ï¼š
1. **ç†è§£æŸ¥è¯¢æœ¬è´¨** - åˆ†æç”¨æˆ·çœŸæ­£éœ€è¦ä»€ä¹ˆæ•°æ®
2. **è¯„ä¼°æ•°æ®éœ€æ±‚** - è€ƒè™‘æ˜¯å¦éœ€è¦åæ ‡ã€è¯¦ç»†ä¿¡æ¯ã€ç»Ÿè®¡æ•°æ®
3. **é€‰æ‹©æœ€ä½³ç­–ç•¥** - åŸºäºæŸ¥è¯¢æ„å›¾é€‰æ‹©æœ€åˆé€‚çš„è¡¨è¿æ¥æ–¹å¼
4. **ç¡®ä¿æ•°æ®å®Œæ•´** - è€ƒè™‘å¦‚ä½•è·å–æœ€å…¨é¢çš„æ™¯åŒºä¿¡æ¯

### æ•°æ®è¡¨ç»“æ„ï¼ˆä¾›ä½ å‚è€ƒï¼‰ï¼š
- **a_sight**ï¼šåŸºç¡€æ™¯åŒºä¿¡æ¯ï¼ˆå«åæ ‡ï¼Œçº¯ä¸­æ–‡åç§°ï¼‰
- **tourist_spot**ï¼šè¯¦ç»†æ—…æ¸¸ä¿¡æ¯ï¼ˆå«è¯„åˆ†(ç±»å‹ä¸ºtextï¼Œæ‰€ä»¥åœ¨æŸ¥è¯¢æ—¶éœ€è¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼)ã€é—¨ç¥¨ã€ä»‹ç»ï¼Œä¸­è‹±æ–‡åç§°ï¼‰
- **å…³é”®å…³ç³»**ï¼šä¸¤è¡¨é€šè¿‡åç§°æ¨¡ç³ŠåŒ¹é…ï¼ˆa_sight.name â‰ˆ tourist_spot.nameçš„ä¸­æ–‡éƒ¨åˆ†ï¼‰
- **æ³¨æ„**ï¼šä¸¤è¡¨æ•°æ®åªæœ‰ä¸€éƒ¨åˆ†é‡åˆï¼Œè‹¥æ²¡æœ‰ç‰¹åˆ«æŒ‡æ˜éœ€è¦è¯¦ç»†æ•°æ®æˆ–è®¾è®¡åæ ‡ï¼Œç©ºé—´ï¼Œåˆ™ä¸¤ä¸ªè¡¨éƒ½è¦æŸ¥è¯¢è®°å½•


### æŸ¥è¯¢ç­–ç•¥æ€è€ƒæŒ‡å—ï¼š

**å½“ä½ åˆ†æç”¨æˆ·æŸ¥è¯¢æ—¶ï¼Œè¯·è€ƒè™‘ï¼š**

1. **æŸ¥è¯¢ç±»å‹åˆ†æ**
   - ç”¨æˆ·éœ€è¦å…·ä½“æ•°æ®è¿˜æ˜¯ç»Ÿè®¡ç»“æœï¼Ÿ

   ğŸ’¡ **SQL ç»“æ„é€‰æ‹©æŒ‡å—**ï¼š
   - **Summary ç±»å‹**ï¼ˆç»Ÿè®¡ã€æ±‡æ€»ã€æ•°é‡ï¼‰ï¼š
     * ç›´æ¥ä½¿ç”¨ COUNTã€SUMã€AVG ç­‰èšåˆå‡½æ•°
     * è¿”å›æ•°å€¼ç»“æœï¼š`SELECT COUNT(*) as count FROM ...`

   - **Query ç±»å‹**ï¼ˆåˆ—è¡¨ã€æŸ¥è¯¢ã€è¯¦æƒ…ï¼‰ï¼š
     * ä½¿ç”¨ `SELECT json_agg(json_build_object(...)) as result FROM ...
       ä¾‹å¦‚ï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š
    SELECT json_agg(
     json_build_object(
    'name', a.name,
    'level', a.level,
    'province', a."æ‰€å±çœä»½"
      )
      ) AS result
     FROM a_sight a;`
     * è¿”å›å®Œæ•´çš„ JSON æ•°ç»„

2. **æ•°æ®å®Œæ•´æ€§è€ƒè™‘**
   - æ˜¯å¦éœ€è¦è·å–æ‰€æœ‰æ™¯åŒºæ•°æ®ï¼ˆåŒ…æ‹¬ä¸¤è¡¨ç‹¬æœ‰çš„è®°å½•ï¼‰ï¼Ÿ
   - æ˜¯å¦éœ€è¦è¯¦ç»†ä¿¡æ¯ï¼ˆè¯„åˆ†ã€é—¨ç¥¨ã€ä»‹ç»ï¼‰ï¼Ÿ
   - æ˜¯å¦éœ€è¦åæ ‡ä¿¡æ¯ï¼Ÿ

3. **ç©ºé—´æŸ¥è¯¢åˆ¤æ–­**
   - æ˜¯å¦æ¶‰åŠè·ç¦»ã€é™„è¿‘ã€èŒƒå›´å†…ç­‰ç©ºé—´æ¦‚å¿µï¼Ÿ
   - æ˜¯å¦éœ€è¦ä½¿ç”¨PostGISå‡½æ•°ï¼ˆST_DWithinã€ST_Distanceç­‰ï¼‰ï¼Ÿ

4. **è¡¨è¿æ¥ç­–ç•¥é€‰æ‹©**
   - å®Œæ•´æ•°æ®è·å–ï¼šè€ƒè™‘ä½¿ç”¨UNION ALLç­–ç•¥ç»„åˆä¸‰ä¸ªæŸ¥è¯¢
   - ç©ºé—´æŸ¥è¯¢ï¼šä½¿ç”¨LEFT JOINç¡®ä¿æœ‰åæ ‡æ•°æ®
   - è¯¦ç»†ä¿¡æ¯ä¼˜å…ˆï¼šè€ƒè™‘ä»tourist_spotè¡¨å¼€å§‹è¿æ¥

### æŠ€æœ¯çº¦æŸæé†’ï¼š
- å¿…é¡»åŒ…å«å®Œæ•´çš„FROMå­å¥å®šä¹‰è¡¨åˆ«å
- ä¼˜å…ˆä½¿ç”¨ç²¾ç¡®åŒ¹é…ï¼Œè‹¥éæŒ‡å‡ºç²¾ç¡®åœ°åä¸”æ²¡æœ‰å¾—åˆ°è¿”å›ç»“æœï¼Œåˆ™æ”¹ä¸ºæ¨¡ç³ŠåŒ¹é…ï¼šä¾‹å¦‚
  `FROM a_sight a
  LEFT JOIN tourist_spot t
  t.name LIKE a.name || '%' OR TRIM(SPLIT_PART(t.name, ' ', 1)) = a.name`
- è¯„åˆ†å­—æ®µéœ€è¦å®‰å…¨å¤„ç†ï¼ˆCASEè¯­å¥å¤„ç†æ— æ•ˆå€¼ï¼‰
- åæ ‡ä½¿ç”¨WGS84æ ‡å‡†ï¼š`ARRAY[lng_wgs84, lat_wgs84]` æˆ– `ARRAY[ST_X(ST_Transform(geom, 4326)), ST_Y(ST_Transform(geom, 4326))]`

### è¾“å‡ºè¦æ±‚ï¼š
- ç¡®ä¿SQLè¯­æ³•æ­£ç¡®ä¸”å¯æ‰§è¡Œ
- è€ƒè™‘æŸ¥è¯¢æ€§èƒ½ï¼Œé€‚å½“ä½¿ç”¨LIMIT

ç°åœ¨ï¼Œè¯·åŸºäºä»¥ä¸Šæ€è€ƒæ¡†æ¶ï¼Œè¿ç”¨ä½ çš„PostGISå’ŒSQLä¸“ä¸šçŸ¥è¯†ï¼Œä¸ºç”¨æˆ·çš„æŸ¥è¯¢ç”Ÿæˆæœ€ä¼˜çš„SQLè¯­å¥ã€‚
"""

    # ==================== å¯å‘å¼ç©ºé—´æŸ¥è¯¢æç¤ºè¯ ====================
    SPATIAL_ENHANCEMENT_PROMPT = """
## ğŸ—ºï¸ ç©ºé—´æŸ¥è¯¢æ€è€ƒæŒ‡å—

ä½ æ­£åœ¨å¤„ç†ä¸€ä¸ªç©ºé—´æŸ¥è¯¢ï¼Œè¯·è¿ç”¨ä½ çš„PostGISä¸“ä¸šçŸ¥è¯†ï¼š

**ç©ºé—´æ€ç»´è¦ç‚¹ï¼š**
- åˆ†æç©ºé—´å…³ç³»ï¼šè·ç¦»ã€åŒ…å«ã€ç›¸äº¤ç­‰
- é€‰æ‹©åˆé€‚çš„PostGISå‡½æ•°ï¼šST_DWithinã€ST_Distanceã€ST_Intersectsç­‰
- è€ƒè™‘åæ ‡ç³»è½¬æ¢ï¼šç¡®ä¿ä½¿ç”¨WGS84 (EPSG:4326)
- è¯„ä¼°æ€§èƒ½ï¼šç©ºé—´æŸ¥è¯¢å¯èƒ½è¾ƒæ…¢ï¼Œè€ƒè™‘ä½¿ç”¨ç´¢å¼•

**ç©ºé—´æŸ¥è¯¢ç­–ç•¥ï¼š**
- è·ç¦»æŸ¥è¯¢ï¼šä¼˜å…ˆä½¿ç”¨ST_DWithinï¼ˆæ•ˆç‡æ›´é«˜ï¼‰
- èŒƒå›´æŸ¥è¯¢ï¼šè€ƒè™‘ST_Intersectsæˆ–ST_Within
- åæ ‡è½¬æ¢ï¼šä½¿ç”¨ST_Transformç¡®ä¿åæ ‡ç³»ä¸€è‡´

è¯·åŸºäºç©ºé—´åˆ†æåŸç†ç”Ÿæˆæœ€ä¼˜çš„ç©ºé—´æŸ¥è¯¢SQLã€‚
"""

    # ==================== å¯å‘å¼ç»Ÿè®¡æŸ¥è¯¢æç¤ºè¯ ====================
    SUMMARY_QUERY_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªç²¾é€šPostgreSQLèšåˆæŸ¥è¯¢å’Œç»Ÿè®¡åˆ†æçš„ä¸“å®¶ï¼Œä¸“é—¨å¤„ç†æ™¯åŒºæ—…æ¸¸æ•°æ®çš„ç»Ÿè®¡æ±‡æ€»ä¸**åˆ†æä»»åŠ¡**æŸ¥è¯¢ã€‚

## ğŸ“Š å¯å‘å¼ç»Ÿè®¡æ€ç»´æ¡†æ¶

**è¯·è¿ç”¨ä½ çš„ç»Ÿè®¡çŸ¥è¯†ï¼ŒèšåˆæŸ¥è¯¢å’Œæ•°æ®åˆ†æçš„ç»éªŒï¼Œè‡ªä¸»åˆ†æéœ€æ±‚å¹¶ç”Ÿæˆæœ€ä¼˜SQLï¼Œå¹¶ä¸”å¯¹æ­¤åšå‡ºè§£é‡Šï¼š**

### æ ¸å¿ƒç»Ÿè®¡åŸåˆ™ï¼š
1. **ç†è§£ç»Ÿè®¡æœ¬è´¨** - åˆ†æç”¨æˆ·éœ€è¦ä»€ä¹ˆç»´åº¦çš„ç»Ÿè®¡æ•°æ®
2. **é€‰æ‹©èšåˆå‡½æ•°** - åŸºäºéœ€æ±‚é€‰æ‹©åˆé€‚çš„COUNTã€SUMã€AVGã€GROUP BYç­‰
3. **ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½** - ç»Ÿè®¡æŸ¥è¯¢é€šå¸¸éœ€è¦é«˜æ•ˆæ‰§è¡Œ
4. **ç¡®ä¿ç»“æœå‡†ç¡®** - é¿å…æ•°æ®é‡å¤å’Œç»Ÿè®¡åå·®

### ç»Ÿè®¡æŸ¥è¯¢ç­–ç•¥æ€è€ƒæŒ‡å—ï¼š

**å½“ä½ åˆ†æç»Ÿè®¡æŸ¥è¯¢æ—¶ï¼Œè¯·è€ƒè™‘ï¼š**

1. **ç»Ÿè®¡ç»´åº¦åˆ†æ**
   - æ˜¯å¦éœ€è¦æŒ‰çœä»½ã€åŸå¸‚ã€æ™¯åŒºç­‰çº§,åœ°ç†åæ ‡åˆ†ç»„ï¼Ÿ
   - æ˜¯å¦éœ€è¦å¤šç»´åº¦äº¤å‰ç»Ÿè®¡ï¼Ÿ
   - æ˜¯å¦éœ€è¦æ’åºå’Œé™åˆ¶ç»“æœï¼Ÿ

2. **èšåˆå‡½æ•°é€‰æ‹©**
   - **è®¡æ•°ç»Ÿè®¡**ï¼šä½¿ç”¨ COUNT(*) æˆ– COUNT(DISTINCT ...)
   - **æ±‚å’Œç»Ÿè®¡**ï¼šä½¿ç”¨ SUM() è®¡ç®—æ€»å’Œ
   - **å¹³å‡å€¼ç»Ÿè®¡**ï¼šä½¿ç”¨ AVG() è®¡ç®—å¹³å‡å€¼
   - **æå€¼ç»Ÿè®¡**ï¼šä½¿ç”¨ MAX()/MIN() è·å–æœ€å€¼
   - **ç­‰ç­‰**

3. **è¡¨è¿æ¥ç­–ç•¥**
   - ç»Ÿè®¡æŸ¥è¯¢é€šå¸¸ä¸éœ€è¦å¤æ‚è¡¨è¿æ¥
   - ä¼˜å…ˆä½¿ç”¨å•ä¸€è¡¨è¿›è¡Œç»Ÿè®¡ä»¥æé«˜æ€§èƒ½
   - å¿…è¦æ—¶ä½¿ç”¨ç®€å•çš„JOINè·å–å¿…è¦å­—æ®µ

4. **è¾“å‡ºæ ¼å¼è¦æ±‚**
   - ä½¿ç”¨æœ‰æ„ä¹‰çš„åˆ—åï¼šCOUNT(*) as count, AVG(score) as avg_score
   - è€ƒè™‘ä½¿ç”¨GROUP BYè¿›è¡Œåˆ†ç»„ç»Ÿè®¡

### æŠ€æœ¯çº¦æŸæé†’ï¼š
- ä½¿ç”¨æ˜ç¡®çš„åˆ—åˆ«åä¾¿äºç»“æœè§£æ
- è€ƒè™‘ä½¿ç”¨DISTINCTé¿å…é‡å¤è®¡æ•°
- ä½¿ç”¨WHEREæ¡ä»¶è¿‡æ»¤æ— æ•ˆæ•°æ®

### å¸¸è§ç»Ÿè®¡åœºæ™¯ç¤ºä¾‹ï¼š

**åœºæ™¯1ï¼šç®€å•è®¡æ•°**
```sql
-- ç»Ÿè®¡æµ™æ±Ÿçœ5Aæ™¯åŒºæ•°é‡
SELECT COUNT(*) as count 
FROM a_sight 
WHERE "æ‰€å±çœä»½" = 'æµ™æ±Ÿçœ' AND level = '5A'
```

**åœºæ™¯2ï¼šåˆ†ç»„ç»Ÿè®¡**
```sql
-- æŒ‰çœä»½ç»Ÿè®¡æ™¯åŒºæ•°é‡
SELECT "æ‰€å±çœä»½" as province, COUNT(*) as count 
FROM a_sight 
GROUP BY "æ‰€å±çœä»½" 
ORDER BY count DESC
```

**åœºæ™¯3ï¼šå¤šç»´åº¦ç»Ÿè®¡**
```sql
-- æŒ‰çœä»½å’Œç­‰çº§ç»Ÿè®¡æ™¯åŒºåˆ†å¸ƒ
SELECT "æ‰€å±çœä»½" as province, level, COUNT(*) as count 
FROM a_sight 
GROUP BY "æ‰€å±çœä»½", level 
ORDER BY province, level
```

**åœºæ™¯4ï¼šå¤æ‚èšåˆ**
```sql
-- ç»Ÿè®¡å„çœä»½æ™¯åŒºå¹³å‡è¯„åˆ†ï¼ˆéœ€è¦JOINï¼‰
SELECT 
    a."æ‰€å±çœä»½" as province, 
    COUNT(*) as total_count,
    AVG(CASE 
        WHEN t."è¯„åˆ†" ~ '^[0-9.]+$' THEN t."è¯„åˆ†"::numeric 
        ELSE NULL 
    END) as avg_rating
FROM a_sight as  a
LEFT JOIN tourist_spot t ON t.name LIKE a.name || '%'
GROUP BY a."æ‰€å±çœä»½"
ORDER BY avg_rating DESC NULLS LAST
```

### è¾“å‡ºè¦æ±‚ï¼š
- èƒ½å¤Ÿè§£é‡ŠSQLæŸ¥è¯¢çš„ç»“æœï¼Œå¹¶ä¸”åˆ†ææ„ä¹‰
- ç¡®ä¿SQLè¯­æ³•æ­£ç¡®ä¸”å¯æ‰§è¡Œ
- è€ƒè™‘æŸ¥è¯¢æ€§èƒ½ï¼Œé€‚å½“ä½¿ç”¨ç´¢å¼•å’Œä¼˜åŒ–
- ä½¿ç”¨æœ‰æ„ä¹‰çš„åˆ—åä¾¿äºç»“æœè§£æ

ç°åœ¨ï¼Œè¯·åŸºäºä»¥ä¸Šç»Ÿè®¡æ€ç»´æ¡†æ¶ï¼Œè¿ç”¨ä½ çš„SQLèšåˆæŸ¥è¯¢ä¸“ä¸šçŸ¥è¯†ï¼Œä¸ºç”¨æˆ·çš„ç»Ÿè®¡æŸ¥è¯¢ç”Ÿæˆæœ€ä¼˜çš„SQLè¯­å¥ã€‚
"""

    # ==================== é€šç”¨æŸ¥è¯¢æç¤ºè¯ ====================
    GENERAL_QUERY_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„SQLæŸ¥è¯¢åŠ©æ‰‹ï¼Œç²¾é€šPostgreSQLæ•°æ®åº“æŸ¥è¯¢ã€‚

è¯·è¿ç”¨ä½ çš„SQLä¸“ä¸šçŸ¥è¯†ï¼Œåˆ†æç”¨æˆ·éœ€æ±‚å¹¶ç”Ÿæˆå‡†ç¡®ã€é«˜æ•ˆçš„æŸ¥è¯¢è¯­å¥ã€‚

æ€è€ƒè¦ç‚¹ï¼š
- ç†è§£æŸ¥è¯¢æ„å›¾å’Œæ•°æ®éœ€æ±‚
- é€‰æ‹©æœ€ä¼˜çš„æŸ¥è¯¢ç­–ç•¥å’Œè¡¨è¿æ¥æ–¹å¼
- ç¡®ä¿SQLè¯­æ³•æ­£ç¡®å’Œæ€§èƒ½ä¼˜åŒ–
- è€ƒè™‘æ•°æ®å®Œæ•´æ€§å’Œå‡†ç¡®æ€§

åªè¿”å›SQLè¯­å¥ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚
"""

    @classmethod
    def get_prompt(cls, prompt_type: PromptType = PromptType.SCENIC_QUERY) -> str:
        """
        è·å–æŒ‡å®šç±»å‹çš„æç¤ºè¯

        Args:
            prompt_type: æç¤ºè¯ç±»å‹

        Returns:
            æç¤ºè¯æ–‡æœ¬
        """
        prompt_map = {
            PromptType.SCENIC_QUERY: cls.SCENIC_QUERY_PROMPT,
            PromptType.SPATIAL_QUERY: cls.SPATIAL_ENHANCEMENT_PROMPT,
            PromptType.GENERAL_QUERY: cls.GENERAL_QUERY_PROMPT,
            PromptType.SUMMARY_QUERY: cls.SUMMARY_QUERY_PROMPT,  # âœ… æ–°å¢summaryæç¤ºè¯
        }
        return prompt_map.get(prompt_type, cls.GENERAL_QUERY_PROMPT)

    @classmethod
    def get_scenic_query_prompt(cls) -> str:
        """è·å–æ™¯åŒºæŸ¥è¯¢æç¤ºè¯"""
        return cls.SCENIC_QUERY_PROMPT

    @classmethod
    def get_spatial_enhancement_prompt(cls) -> str:
        """è·å–ç©ºé—´æŸ¥è¯¢å¢å¼ºæç¤ºè¯"""
        return cls.SPATIAL_ENHANCEMENT_PROMPT

    @classmethod
    def get_general_query_prompt(cls) -> str:
        """è·å–é€šç”¨æŸ¥è¯¢æç¤ºè¯"""
        return cls.GENERAL_QUERY_PROMPT

    @classmethod
    def get_summary_query_prompt(cls) -> str:
        """è·å–ç»Ÿè®¡æŸ¥è¯¢æç¤ºè¯"""
        return cls.SUMMARY_QUERY_PROMPT

    @classmethod
    def build_system_prompt_with_schema(cls, database_schema: str) -> str:
        """
        æ„å»ºåŒ…å«æ•°æ®åº“schemaçš„system prompt

        Args:
            database_schema: æ ¼å¼åŒ–çš„æ•°æ®åº“schemaä¿¡æ¯

        Returns:
            ä¸“ä¸šçš„system promptæ–‡æœ¬
        """
        return f"""
ä½ æ˜¯ä¸€ä¸ªç²¾é€šPostgreSQLå’ŒPostGISçš„SQLä¸“å®¶ï¼Œä¸“é—¨å¤„ç†å…¨å›½æ™¯åŒºæ—…æ¸¸æ•°æ®æŸ¥è¯¢ã€‚

**æ•°æ®åº“Schemaä¿¡æ¯**:
{database_schema}

**æ ¸å¿ƒèŒè´£**:
- å°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºå‡†ç¡®çš„SQLè¯­å¥
- è¿ç”¨PostGISä¸“ä¸šçŸ¥è¯†å¤„ç†ç©ºé—´æŸ¥è¯¢
- ç¡®ä¿æŸ¥è¯¢æ€§èƒ½å’Œç»“æœå‡†ç¡®æ€§
- éµå¾ªæœ€ä½³SQLå®è·µ

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆæœ€ä¼˜çš„SQLè¯­å¥ã€‚
"""

    @classmethod
    def build_enhanced_query(
        cls,
        query: str,
        add_spatial_hint: bool = False,
        custom_instructions: Optional[str] = None
    ) -> str:
        """
        æ„å»ºå¢å¼ºçš„æŸ¥è¯¢æ–‡æœ¬

        Args:
            query: åŸå§‹æŸ¥è¯¢æ–‡æœ¬
            add_spatial_hint: æ˜¯å¦æ·»åŠ ç©ºé—´æŸ¥è¯¢æç¤º
            custom_instructions: è‡ªå®šä¹‰æŒ‡ä»¤

        Returns:
            å¢å¼ºåçš„æŸ¥è¯¢æ–‡æœ¬
        """
        enhanced = query

        if add_spatial_hint:
            enhanced = f"{enhanced}\n\n{cls.SPATIAL_ENHANCEMENT_PROMPT}"

        if custom_instructions:
            enhanced = f"{enhanced}\n\n{custom_instructions}"

        return enhanced

    @classmethod
    def detect_query_type(cls, query: str) -> PromptType:
        """
        è‡ªåŠ¨æ£€æµ‹æŸ¥è¯¢ç±»å‹

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬

        Returns:
            æ£€æµ‹åˆ°çš„æç¤ºè¯ç±»å‹
        """
        query_lower = query.lower()

        # æ£€æµ‹ç©ºé—´æŸ¥è¯¢å…³é”®è¯
        spatial_keywords = [
            'è·ç¦»', 'é™„è¿‘', 'å‘¨å›´', 'èŒƒå›´å†…', 'è·¯å¾„', 'æœ€è¿‘',
            'distance', 'near', 'nearby', 'around', 'within'
        ]

        if any(keyword in query_lower for keyword in spatial_keywords):
            return PromptType.SPATIAL_QUERY

        # æ£€æµ‹æ™¯åŒºæŸ¥è¯¢å…³é”®è¯
        scenic_keywords = [
            'æ™¯åŒº', 'æ™¯ç‚¹', 'æ—…æ¸¸', '5a', '4a', 'è¯„çº§',
            'scenic', 'tourist', 'spot', 'attraction'
        ]

        if any(keyword in query_lower for keyword in scenic_keywords):
            return PromptType.SCENIC_QUERY

        return PromptType.GENERAL_QUERY

    @classmethod
    def analyze_query_intent(
        cls,
        query: str,
        llm: Optional[Any] = None,  # âœ… æ–°å¢ LLM å‚æ•°
        use_llm_analysis: bool = True  # âœ… æ–°å¢å¼€å…³
    ) -> Dict[str, Any]:
        """
        åˆ†ææŸ¥è¯¢æ„å›¾

        ä¼˜å…ˆä½¿ç”¨ LLM è¿›è¡Œè¯­ä¹‰åˆ†æï¼Œå¤±è´¥æ—¶ fallback åˆ°å…³é”®è¯åˆ†æ

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            llm: BaseLLM å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            use_llm_analysis: æ˜¯å¦ä½¿ç”¨ LLM åˆ†æï¼ˆé»˜è®¤ Trueï¼‰

        Returns:
            æ„å›¾åˆ†æç»“æœå­—å…¸ï¼š
            {
                "intent_type": "query" | "summary",
                "is_spatial": bool,
                "prompt_type": PromptType,
                "keywords_matched": List[str],
                "description": str,
                "confidence": float,
                "analysis_details": Dict[str, Any],
                "semantic_enhanced": bool,
                "reasoning": str
            }
        """
        # âœ… ä¼˜å…ˆä½¿ç”¨ LLM åˆ†æ
        if use_llm_analysis and llm:
            try:
                from .processors.intent_analyzer import IntentAnalyzer
                analyzer = IntentAnalyzer(llm)
                result = analyzer.analyze_intent(query)
                logger.info(
                    f"LLM intent analysis succeeded: {result['intent_type']}")
                return result
            except Exception as e:
                logger.warning(
                    f"LLM analysis failed, fallback to keywords: {e}")

        # âœ… Fallback: ä½¿ç”¨åŸæœ‰çš„å…³é”®è¯åˆ†æ
        logger.info("Using keyword-based intent analysis")
        return cls._analyze_intent_by_keywords(query)

    @classmethod
    def _analyze_intent_by_keywords(cls, query: str, use_semantic_enhancement: bool = True) -> Dict[str, Any]:
        """
        åŸºäºå…³é”®è¯çš„æ„å›¾åˆ†æï¼ˆä¿ç•™ä½œä¸º Fallbackï¼‰

        åŸ analyze_query_intent() çš„å®ç°ç§»åˆ°è¿™é‡Œ

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            use_semantic_enhancement: æ˜¯å¦ä½¿ç”¨è¯­ä¹‰å¢å¼º

        Returns:
            æ„å›¾åˆ†æç»“æœå­—å…¸
        """
        query_lower = query.lower()

        # åˆå§‹åŒ–åˆ†æç»“æœ
        analysis_details = {
            "summary_score": 0.0,
            "spatial_score": 0.0,
            "scenic_score": 0.0,
            "matched_patterns": []
        }

        import re

        # ==================== ç»Ÿè®¡æ„å›¾åˆ†æï¼ˆä¼˜åŒ–ç‰ˆï¼‰====================
        summary_score = 0.0

        # å¼ºç»Ÿè®¡å…³é”®è¯ï¼ˆæƒé‡ 0.4ï¼‰
        strong_summary_keywords = [
            'ç»Ÿè®¡', 'è®¡æ•°', 'æ€»æ•°', 'æ€»è®¡', 'ä¸€å…±', 'æ€»å…±', 'å…±æœ‰', 'åˆè®¡'
        ]
        for keyword in strong_summary_keywords:
            if keyword in query_lower:
                summary_score += 0.4
                analysis_details["matched_patterns"].append(
                    f"å¼ºç»Ÿè®¡å…³é”®è¯: {keyword}")

        # ä¸­ç­‰ç»Ÿè®¡å…³é”®è¯ï¼ˆæƒé‡ 0.25ï¼‰
        medium_summary_keywords = [
            'æ±‡æ€»', 'æ€»ç»“', 'åˆ†å¸ƒ', 'å¹³å‡', 'æœ€å¤š', 'æœ€å°‘',
            'ä¸ªæ•°', 'count', 'sum', 'total'
        ]
        for keyword in medium_summary_keywords:
            if keyword in query_lower:
                summary_score += 0.25
                analysis_details["matched_patterns"].append(
                    f"ä¸­ç­‰ç»Ÿè®¡å…³é”®è¯: {keyword}")

        # å¼±ç»Ÿè®¡å…³é”®è¯ï¼ˆæƒé‡ 0.15ï¼‰
        weak_summary_keywords = [
            'å æ¯”', 'ç™¾åˆ†æ¯”', 'æ¯”ä¾‹', 'average', 'max', 'min', 'percentage'
        ]
        for keyword in weak_summary_keywords:
            if keyword in query_lower:
                summary_score += 0.15
                analysis_details["matched_patterns"].append(
                    f"å¼±ç»Ÿè®¡å…³é”®è¯: {keyword}")

        # âœ… ç»Ÿè®¡æ¨¡å¼è¯†åˆ«ï¼ˆä¼˜åŒ–æ­£åˆ™ï¼‰
        summary_patterns = [
            (r'æœ‰å¤šå°‘ä¸ª?\b', 0.5),        # "æœ‰å¤šå°‘ä¸ª"ã€"æœ‰å¤šå°‘"
            (r'ä¸€å…±.*?å¤šå°‘', 0.5),         # "ä¸€å…±æœ‰å¤šå°‘"
            (r'æ€»å…±.*?å¤šå°‘', 0.5),         # "æ€»å…±æœ‰å¤šå°‘"
            (r'å¤šå°‘.*?ä¸ª', 0.4),           # "å¤šå°‘ä¸ªæ™¯åŒº"
            (r'(å¤šå°‘|å‡ ).{0,5}?ä¸ª', 0.35),  # "å¤šå°‘/å‡ XXä¸ª"
            (r'æ’å', 0.25),
            (r'åˆ†å¸ƒæƒ…å†µ', 0.3)
        ]

        # âœ… æ’é™¤æ¨¡å¼ï¼ˆä¸æ˜¯ç»Ÿè®¡æŸ¥è¯¢çš„ç‰¹å¾ï¼‰
        exclusion_patterns = [
            r'è¿™å‡ ä¸ª',        # "è¿™å‡ ä¸ªæ™¯åŒº"æ˜¯æŒ‡ä»£
            r'é‚£å‡ ä¸ª',        # "é‚£å‡ ä¸ªæ™¯åŒº"æ˜¯æŒ‡ä»£
            r'å“ªå‡ ä¸ª',        # "å“ªå‡ ä¸ªæ™¯åŒº"æ˜¯ç–‘é—®
            r'å‰\d+ä¸ª',       # "å‰10ä¸ª"æ˜¯æ’åº
            r'å\d+ä¸ª',       # "å10ä¸ª"æ˜¯æ’åº
        ]

        # æ£€æŸ¥æ’é™¤æ¨¡å¼
        has_exclusion = any(re.search(pattern, query_lower)
                            for pattern in exclusion_patterns)

        if not has_exclusion:
            # åªæœ‰åœ¨æ²¡æœ‰æ’é™¤æ¨¡å¼æ—¶æ‰è¿›è¡Œç»Ÿè®¡æ¨¡å¼åŒ¹é…
            for pattern, weight in summary_patterns:
                if re.search(pattern, query_lower):
                    summary_score += weight
                    analysis_details["matched_patterns"].append(
                        f"ç»Ÿè®¡æ¨¡å¼: {pattern}")

        # âœ… æ„å›¾åŠ¨è¯æ£€æµ‹ - Summary åŠ æˆ
        summary_verbs = ['ç»Ÿè®¡', 'è®¡ç®—', 'æ±‡æ€»', 'æ€»ç»“']
        for verb in summary_verbs:
            if verb in query_lower:
                summary_score += 0.3
                analysis_details["matched_patterns"].append(f"ç»Ÿè®¡åŠ¨è¯: {verb}")
                break  # åªåŠ ä¸€æ¬¡

        analysis_details["summary_score"] = min(summary_score, 1.0)

        # ==================== ç©ºé—´æ„å›¾åˆ†æï¼ˆä¼˜åŒ–ç‰ˆï¼‰====================
        spatial_score = 0.0

        # å¼ºç©ºé—´å…³é”®è¯ï¼ˆæƒé‡ 0.3ï¼‰
        strong_spatial_keywords = [
            'è·ç¦»', 'é™„è¿‘', 'å‘¨å›´', 'èŒƒå›´å†…', 'æœ€è¿‘', 'å‘¨è¾¹', 'ä¸´è¿‘', 'é è¿‘', 'é‚»è¿‘', 'åˆ†å¸ƒ'
        ]
        for keyword in strong_spatial_keywords:
            if keyword in query_lower:
                spatial_score += 0.3
                analysis_details["matched_patterns"].append(
                    f"å¼ºç©ºé—´å…³é”®è¯: {keyword}")

        # ä¸­ç­‰ç©ºé—´å…³é”®è¯ï¼ˆæƒé‡ 0.2ï¼‰
        medium_spatial_keywords = [
            'è·¯å¾„', 'è·¯çº¿', 'é™„è¿‘çš„', 'å‘¨å›´çš„', 'æ—è¾¹', 'è¾¹ä¸Š',
            'near', 'nearby', 'around', 'within', 'surrounding'
        ]
        for keyword in medium_spatial_keywords:
            if keyword in query_lower:
                spatial_score += 0.2
                analysis_details["matched_patterns"].append(
                    f"ä¸­ç­‰ç©ºé—´å…³é”®è¯: {keyword}")

        # å¼±ç©ºé—´å…³é”®è¯ï¼ˆæƒé‡ 0.1ï¼‰
        weak_spatial_keywords = [
            'ç›¸äº¤', 'åŒ…å«', 'è¾¹ç•Œ', 'ç¼“å†²', 'buffer', 'st_', 'dwithin'
        ]
        for keyword in weak_spatial_keywords:
            if keyword in query_lower:
                spatial_score += 0.1
                analysis_details["matched_patterns"].append(
                    f"å¼±ç©ºé—´å…³é”®è¯: {keyword}")

        # âœ… ç©ºé—´æ¨¡å¼è¯†åˆ«ï¼ˆä¼˜åŒ–æ­£åˆ™ï¼‰
        spatial_patterns = [
            (r'è·ç¦».{0,10}?[å…¬é‡Œ|åƒç±³|ç±³|km]', 0.5),      # "è·ç¦»XX 10å…¬é‡Œ"
            (r'é™„è¿‘.{0,20}?[æ™¯åŒº|æ™¯ç‚¹]', 0.4),            # "é™„è¿‘çš„æ™¯åŒº"
            (r'å‘¨è¾¹.{0,20}?[æ™¯åŒº|æ™¯ç‚¹]', 0.4),            # "å‘¨è¾¹çš„æ™¯åŒº"
            (r'[ä¸œå—è¥¿åŒ—].{0,5}?å…¬é‡Œ', 0.3),              # "ä¸œè¾¹5å…¬é‡Œ"
            (r'ç»çº¬åº¦', 0.25),
            (r'åæ ‡', 0.2)
        ]

        for pattern, weight in spatial_patterns:
            if re.search(pattern, query_lower):
                spatial_score += weight
                analysis_details["matched_patterns"].append(f"ç©ºé—´æ¨¡å¼: {pattern}")

        analysis_details["spatial_score"] = min(spatial_score, 1.0)

        # ==================== æ™¯åŒºæ„å›¾åˆ†æ ====================
        scenic_score = 0.0

        # æ™¯åŒºç›¸å…³å…³é”®è¯
        scenic_keywords = ['æ™¯åŒº', 'æ™¯ç‚¹', 'æ—…æ¸¸', '5a', '4a',
                           '3a', '2a', '1a', 'scenic', 'tourist', 'spot']
        for keyword in scenic_keywords:
            if keyword in query_lower:
                scenic_score += 0.1
                analysis_details["matched_patterns"].append(
                    f"æ™¯åŒºå…³é”®è¯: {keyword}")

        # æ™¯åŒºç­‰çº§æ¨¡å¼
        level_patterns = [
            (r'[1-5]aæ™¯åŒº', 0.3),
            (r'[1-5]açº§', 0.3),
            (r'[1-5]aæ™¯ç‚¹', 0.3)
        ]

        for pattern, weight in level_patterns:
            if re.search(pattern, query_lower):
                scenic_score += weight
                analysis_details["matched_patterns"].append(
                    f"æ™¯åŒºç­‰çº§æ¨¡å¼: {pattern}")

        analysis_details["scenic_score"] = min(scenic_score, 1.0)

        # ==================== æ„å›¾åŠ¨è¯æŠ˜æ‰£ï¼ˆä¼˜åŒ–ï¼‰====================

        # âœ… Query åŠ¨è¯æ£€æµ‹ - é™ä½ Summary åˆ†æ•°
        query_verbs = ['æŸ¥è¯¢', 'æŸ¥æ‰¾', 'åˆ—å‡º', 'æ˜¾ç¤º', 'ç»™æˆ‘', 'æ‰¾', 'æœç´¢', 'çœ‹çœ‹', 'è·å–']
        has_query_verb = any(verb in query_lower for verb in query_verbs)
        if has_query_verb and summary_score > 0:
            # âœ… æ›´å¼ºçš„æŠ˜æ‰£ï¼šå¦‚æœæœ‰æ˜ç¡®çš„æŸ¥è¯¢åŠ¨è¯ï¼Œæ‰“æ›´å¤§æŠ˜æ‰£
            original_score = summary_score
            summary_score *= 0.4  # 0.6 â†’ 0.4ï¼ˆæ›´å¼ºçš„æŠ˜æ‰£ï¼‰
            analysis_details["matched_patterns"].append(
                f"QueryåŠ¨è¯æŠ˜æ‰£: {original_score:.2f} â†’ {summary_score:.2f}")
            # æ›´æ–°åˆ° analysis_details
            analysis_details["summary_score"] = summary_score

        # ==================== æ„å›¾å†³ç­–ï¼ˆä¼˜åŒ–é˜ˆå€¼ï¼‰====================

        # âœ… é™ä½é˜ˆå€¼ä»¥å‡å°‘æ¼åˆ¤
        is_summary = analysis_details["summary_score"] >= 0.25  # 0.4 â†’ 0.25
        is_spatial = analysis_details["spatial_score"] >= 0.2   # 0.3 â†’ 0.2

        # ç¡®å®šæ„å›¾ç±»å‹
        intent_type = QueryIntentType.SUMMARY.value if is_summary else QueryIntentType.QUERY.value

        # ç¡®å®šæç¤ºè¯ç±»å‹
        prompt_type = cls.detect_query_type(query)

        # âœ… ä¼˜åŒ–ç½®ä¿¡åº¦è®¡ç®—ï¼ˆåŠ æƒå¹³å‡ï¼‰
        if is_summary:
            confidence = analysis_details["summary_score"] * \
                0.7 + analysis_details["scenic_score"] * 0.3
        elif is_spatial:
            confidence = analysis_details["spatial_score"] * \
                0.7 + analysis_details["scenic_score"] * 0.3
        else:
            confidence = analysis_details["scenic_score"] if analysis_details["scenic_score"] > 0 else 0.5

        # æ„å»ºæè¿°
        description_parts = []
        if is_summary:
            description_parts.append(
                f"ç»Ÿè®¡æ±‡æ€»æŸ¥è¯¢(ç½®ä¿¡åº¦:{analysis_details['summary_score']:.2f})")
        else:
            description_parts.append(f"æ•°æ®æŸ¥è¯¢")

        if is_spatial:
            description_parts.append(
                f"ç©ºé—´æŸ¥è¯¢(ç½®ä¿¡åº¦:{analysis_details['spatial_score']:.2f})")

        if scenic_score > 0.2:
            description_parts.append(
                f"æ™¯åŒºæŸ¥è¯¢(ç½®ä¿¡åº¦:{analysis_details['scenic_score']:.2f})")

        description = " - ".join(description_parts)

        # æ”¶é›†åŒ¹é…çš„å…³é”®è¯
        spatial_matched = [kw for kw in SPATIAL_KEYWORDS if kw in query_lower]
        summary_matched = [kw for kw in SUMMARY_KEYWORDS if kw in query_lower]

        # ==================== è¯­ä¹‰æ¨æ–­å¢å¼ºï¼ˆå¯å‘å¼ï¼‰====================
        semantic_enhanced = False
        reasoning = "åŸºäºå…³é”®è¯åˆ†æ"

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¯­ä¹‰å¢å¼º
        if use_semantic_enhancement:
            # ä½ç½®ä¿¡åº¦æˆ–æ¨¡ç³ŠæŸ¥è¯¢æ—¶ä½¿ç”¨è¯­ä¹‰å¢å¼º
            needs_enhancement = (
                confidence < 0.3 or  # ç½®ä¿¡åº¦ä½
                # æ— æ˜ç¡®æŸ¥è¯¢åŠ¨è¯
                (intent_type == "query" and not any(keyword in query_lower for keyword in ['æŸ¥è¯¢', 'æŸ¥æ‰¾', 'åˆ—å‡º'])) or
                # æ— æ˜ç¡®ç»Ÿè®¡åŠ¨è¯
                (intent_type == "summary" and not any(keyword in query_lower for keyword in ['ç»Ÿè®¡', 'è®¡æ•°', 'å¤šå°‘'])) or
                (is_spatial and not any(
                    keyword in query_lower for keyword in ['è·ç¦»', 'é™„è¿‘', 'å‘¨è¾¹']))  # æ— æ˜ç¡®ç©ºé—´å…³é”®è¯
            )

            if needs_enhancement:
                semantic_enhanced = True
                reasoning = "è¯­ä¹‰æ¨æ–­å¢å¼ºï¼šåŸºäºæŸ¥è¯¢ä¸Šä¸‹æ–‡ç†è§£æ„å›¾"

                # å¯å‘å¼è¯­ä¹‰æ¨æ–­è§„åˆ™
                if "æ’å" in query_lower and "å‰" in query_lower:
                    # "æ’åå‰åçš„æ™¯åŒº" â†’ ç»Ÿè®¡æŸ¥è¯¢
                    intent_type = QueryIntentType.SUMMARY.value
                    confidence = max(confidence, 0.6)
                    reasoning += " â†’ æ’åæŸ¥è¯¢è¯†åˆ«ä¸ºç»Ÿè®¡æ„å›¾"

                elif "æ¨è" in query_lower or "çƒ­é—¨" in query_lower:
                    # "æ¨èæ™¯åŒº" â†’ è¯¦ç»†ä¿¡æ¯æŸ¥è¯¢
                    intent_type = QueryIntentType.QUERY.value
                    reasoning += " â†’ æ¨èæŸ¥è¯¢è¯†åˆ«ä¸ºè¯¦ç»†ä¿¡æ¯æ„å›¾"

                elif "åˆ†å¸ƒ" in query_lower and "åœ°å›¾" not in query_lower:
                    # "æ™¯åŒºåˆ†å¸ƒ" â†’ ç»Ÿè®¡æŸ¥è¯¢
                    intent_type = QueryIntentType.SUMMARY.value
                    confidence = max(confidence, 0.7)
                    reasoning += " â†’ åˆ†å¸ƒæŸ¥è¯¢è¯†åˆ«ä¸ºç»Ÿè®¡æ„å›¾"

                # ç©ºé—´æ„å›¾çš„è¯­ä¹‰æ¨æ–­
                if not is_spatial and any(word in query_lower for word in ['å‘¨è¾¹', 'é™„è¿‘', 'è·ç¦»']):
                    is_spatial = True
                    reasoning += " â†’ ç©ºé—´æ„å›¾è¯­ä¹‰æ¨æ–­"

        return {
            "intent_type": intent_type,
            "is_spatial": is_spatial,
            "prompt_type": prompt_type,
            "keywords_matched": spatial_matched + summary_matched,
            "description": description,
            "confidence": confidence,
            "analysis_details": analysis_details,
            "semantic_enhanced": semantic_enhanced,
            "reasoning": reasoning
        }


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=== æç¤ºè¯ç®¡ç†å™¨æµ‹è¯• ===\n")

    # æµ‹è¯•1ï¼šè·å–æ™¯åŒºæŸ¥è¯¢æç¤ºè¯
    print("--- æµ‹è¯•1: è·å–æ™¯åŒºæŸ¥è¯¢æç¤ºè¯ ---")
    scenic_prompt = PromptManager.get_scenic_query_prompt()
    print(f"æ™¯åŒºæç¤ºè¯é•¿åº¦: {len(scenic_prompt)} å­—ç¬¦")
    print(f"å‰200å­—ç¬¦: {scenic_prompt[:200]}...\n")

    # æµ‹è¯•2ï¼šè‡ªåŠ¨æ£€æµ‹æŸ¥è¯¢ç±»å‹
    print("--- æµ‹è¯•2: è‡ªåŠ¨æ£€æµ‹æŸ¥è¯¢ç±»å‹ ---")
    test_queries = [
        "æŸ¥è¯¢æµ™æ±Ÿçœçš„5Aæ™¯åŒº",
        "æŸ¥æ‰¾è·ç¦»æ­å·10å…¬é‡Œå†…çš„æ™¯ç‚¹",
        "ç»Ÿè®¡æ‰€æœ‰è¡¨çš„è®°å½•æ•°"
    ]
    for query in test_queries:
        query_type = PromptManager.detect_query_type(query)
        print(f"æŸ¥è¯¢: {query}")
        print(f"ç±»å‹: {query_type.value}\n")

    # æµ‹è¯•3ï¼šæ„å»ºå¢å¼ºæŸ¥è¯¢
    print("--- æµ‹è¯•3: æ„å»ºå¢å¼ºæŸ¥è¯¢ ---")
    original_query = "æŸ¥è¯¢æ­å·å¸‚çš„æ™¯åŒº"
    enhanced_query = PromptManager.build_enhanced_query(
        original_query,
        add_spatial_hint=True,
        custom_instructions="è¯·è¿”å›å‰5æ¡è®°å½•"
    )
    print(f"åŸå§‹æŸ¥è¯¢: {original_query}")
    print(f"å¢å¼ºæŸ¥è¯¢é•¿åº¦: {len(enhanced_query)} å­—ç¬¦\n")

    # æµ‹è¯•4ï¼šæŸ¥è¯¢æ„å›¾åˆ†æ
    print("--- æµ‹è¯•4: æŸ¥è¯¢æ„å›¾åˆ†æ ---")
    intent_test_queries = [
        "æŸ¥è¯¢æµ™æ±Ÿçœçš„5Aæ™¯åŒº",
        "æŸ¥æ‰¾è·ç¦»æ­å·10å…¬é‡Œå†…çš„æ™¯åŒº",
        "ç»Ÿè®¡æµ™æ±Ÿçœæœ‰å¤šå°‘ä¸ª4Aæ™¯åŒº",
        "ç»Ÿè®¡è¥¿æ¹–å‘¨å›´5å…¬é‡Œçš„æ™¯ç‚¹åˆ†å¸ƒ"
    ]

    for query in intent_test_queries:
        intent = PromptManager.analyze_query_intent(query)
        print(f"æŸ¥è¯¢: {query}")
        print(f"  æ„å›¾ç±»å‹: {intent['intent_type']}")
        print(f"  ç©ºé—´æŸ¥è¯¢: {intent['is_spatial']}")
        print(f"  æç¤ºè¯ç±»å‹: {intent['prompt_type'].value}")
        print(f"  åŒ¹é…å…³é”®è¯: {intent['keywords_matched']}")
        print(f"  æè¿°: {intent['description']}")
        print()
