"""
SQLç”Ÿæˆå™¨æ¨¡å— - Sight Server
è´Ÿè´£å°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºSQLè¯­å¥
"""

import logging
import re
from typing import Optional, List, Dict, Any
from langchain_core.prompts import PromptTemplate

logger = logging.getLogger(__name__)


class SQLGenerator:
    """
    SQLç”Ÿæˆå™¨

    åŠŸèƒ½:
    - å°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºSQL
    - æ”¯æŒåˆå§‹æŸ¥è¯¢å’Œåç»­æŸ¥è¯¢
    - åˆ†æç¼ºå¤±ä¿¡æ¯å¹¶ç”Ÿæˆè¡¥å……æŸ¥è¯¢
    """

    def __init__(self, llm, base_prompt: str):
        """
        åˆå§‹åŒ–SQLç”Ÿæˆå™¨

        Args:
            llm: LLMå®ä¾‹ (BaseLLM)
            base_prompt: åŸºç¡€æç¤ºè¯
        """
        self.llm = llm
        self.base_prompt = base_prompt
        self.logger = logger
        self._cached_schema: Optional[str] = None

    def _build_sql_generation_prompt(self, match_mode: str) -> PromptTemplate:
        template = self.sql_generation_template.replace("{match_rules}", self._get_match_rules(match_mode, context="initial"))
        return PromptTemplate(template=template, input_variables=self.sql_generation_inputs)

    def _build_followup_prompt(self, match_mode: str) -> PromptTemplate:
        template = self.followup_query_template.replace("{match_rules}", self._get_match_rules(match_mode, context="followup"))
        return PromptTemplate(template=template, input_variables=self.followup_query_inputs)

    def _get_match_rules(self, match_mode: str, context: str = "initial") -> str:
        if match_mode.lower() == "exact":
            rules = [
                "## ğŸ¯ ç²¾ç¡®åŒ¹é…ç­–ç•¥ï¼ˆæŒ‰éœ€å¯ç”¨ï¼‰",
                "",
                "- æ ¹æ®ç”¨æˆ·æ˜ç¡®è¦æ±‚ï¼Œä½¿ç”¨ `=` å¯¹æ–‡æœ¬å­—æ®µè¿›è¡Œç²¾ç¡®æ¯”è¾ƒã€‚",
                "- å¯ç»“åˆ `LOWER()` / `UPPER()` ç»Ÿä¸€å¤§å°å†™ï¼Œé¿å…é—æ¼ã€‚",
                "- å¦‚éœ€åŒ¹é…å¤šä¸ªå…³é”®è¯ï¼Œå¯ä½¿ç”¨ `IN` æˆ–å¤šæ¡ä»¶ `OR`ã€‚",
                "- æœªæ˜ç¡®è¦æ±‚æ—¶è¯·è°¨æ…ä½¿ç”¨ç²¾ç¡®è¿‡æ»¤ï¼Œä»¥å…é—æ¼ç»“æœã€‚",
            ]
        else:
            rules = [
                "## ğŸ” æ¨¡ç³ŠåŒ¹é…ç­–ç•¥ï¼ˆé»˜è®¤å¯ç”¨ï¼‰",
                "",
                "- å¯¹æ¶‰åŠç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æ¡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ã€‚",
                "- æ¨èä¹¦å†™ `column ILIKE '%' || <value> || '%'` æˆ– `column ILIKE CONCAT('%', <value>, '%')`ã€‚",
                "- ç”¨æˆ·æ˜ç¡®è¦æ±‚â€œç²¾ç¡®åŒ¹é…/å®Œå…¨ä¸€è‡´â€æ—¶å†ä½¿ç”¨ `=`ã€‚",
                "- ç»„åˆå¤šä¸ªå…³é”®å­—æ—¶å¯å…ˆç”¨ `ILIKE` ç„¶åé€šè¿‡ `AND/OR` ç»„åˆã€‚",
            ]
        return "\n".join(rules)

        # âœ… å¯å‘å¼ SQL ç”Ÿæˆ Promptï¼ˆè°ƒåŠ¨ LLM çš„ SQL ä¸“ä¸šçŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼‰
        self.sql_generation_template = """ä½ æ˜¯ä¸€ä¸ªç²¾é€š PostgreSQL å’Œ PostGIS çš„ SQL ä¸“å®¶ã€‚

{base_prompt}

**æ•°æ®åº“Schemaä¿¡æ¯**ï¼ˆå®Œæ•´å­—æ®µç±»å‹ä¾›ä½ å‚è€ƒï¼‰:
{database_schema}

**ç”¨æˆ·æŸ¥è¯¢**: {query}

**æŸ¥è¯¢æ„å›¾åˆ†æ**ï¼ˆä¾›ä½ å‚è€ƒï¼‰:
- æŸ¥è¯¢ç±»å‹: {intent_type} (query=ç”¨æˆ·éœ€è¦å…·ä½“æ•°æ® / summary=ç”¨æˆ·éœ€è¦ç»Ÿè®¡ç»“æœ)
- ç©ºé—´ç‰¹å¾: {is_spatial} (True=æ¶‰åŠè·ç¦»/ä½ç½®è®¡ç®— / False=æ™®é€šæ•°æ®æŸ¥è¯¢)
- ç½®ä¿¡åº¦: {confidence}
- ç›¸å…³å…³é”®è¯: {keywords_matched}

---

## ğŸ“‹ æ„å›¾ç»„åˆå†³ç­–è¡¨ï¼ˆå¿«é€Ÿå†³ç­–æŒ‡å—ï¼‰

æ ¹æ® **intent_type** å’Œ **is_spatial** çš„ç»„åˆï¼Œé€‰æ‹©å¯¹åº”çš„ SQL ç»“æ„ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ intent_type â”‚ is_spatial  â”‚ æŸ¥è¯¢ç¤ºä¾‹                     â”‚ SQL ç»“æ„è¦æ±‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ query       â”‚ False       â”‚ "æŸ¥è¯¢æµ™æ±Ÿçœçš„5Aæ™¯åŒº"         â”‚ json_agg + å®Œæ•´å­—æ®µ        â”‚
â”‚ query       â”‚ True        â”‚ "è·ç¦»è¥¿æ¹–10å…¬é‡Œå†…çš„æ™¯åŒº"     â”‚ json_agg + åæ ‡ + ç©ºé—´è¿‡æ»¤ â”‚
â”‚ summary     â”‚ False       â”‚ "ç»Ÿè®¡æµ™æ±Ÿçœæœ‰å¤šå°‘æ™¯åŒº"       â”‚ COUNT/AVG + å¯é€‰GROUP BY   â”‚
â”‚ summary     â”‚ True â­     â”‚ "æ­¦æ±‰å¸‚æ™¯åŒºçš„ç©ºé—´åˆ†å¸ƒ"       â”‚ GROUP BY + ç©ºé—´å­—æ®µ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**å½“å‰æŸ¥è¯¢å±äº**: {intent_type} + {spatial_type} â†’ è¯·ä¸¥æ ¼éµå®ˆå¯¹åº”çš„ SQL ç»“æ„è¦æ±‚

---

## âš ï¸ CRITICAL RULESï¼ˆç»å¯¹å¿…é¡»éµå®ˆï¼‰

{match_rules}
**æ ¹æ® intent_type å’Œ is_spatial ä¸¥æ ¼é€‰æ‹© SQL ç»“æ„ï¼š**

### ğŸ“Š Summary æŸ¥è¯¢ (intent_type="summary") - è§„åˆ™ï¼š

#### Summary + Non-Spatial (æ™®é€šç»Ÿè®¡æŸ¥è¯¢)
   âœ… **å¿…é¡»ä½¿ç”¨èšåˆå‡½æ•°**: COUNT(*), SUM(...), AVG(...), MAX(...), MIN(...)
   âœ… **å¿…é¡»è¿”å›ç®€å•æ•°å€¼æˆ–åˆ†ç»„ç»Ÿè®¡**
   âœ… **å…è®¸ GROUP BY åˆ†ç»„ç»Ÿè®¡**
   âŒ **ç¦æ­¢ä½¿ç”¨ json_agg æˆ– json_build_object**

   **æ­£ç¡®ç¤ºä¾‹**ï¼š
   ```sql
   -- ç®€å•æ•°é‡ç»Ÿè®¡
   SELECT COUNT(*) as count FROM a_sight WHERE level = '5A'

   -- åˆ†ç»„ç»Ÿè®¡
   SELECT "æ‰€å±çœä»½" as province, COUNT(*) as count
   FROM a_sight GROUP BY "æ‰€å±çœä»½"

   -- å¤šç»´åº¦ç»Ÿè®¡
   SELECT level, COUNT(*) as count 
   FROM a_sight GROUP BY level ORDER BY count DESC
   ```

#### Summary + Spatial (ç©ºé—´ç»Ÿè®¡æŸ¥è¯¢) â­ é‡è¦
   âœ… **å¿…é¡»è¿”å›ç©ºé—´ç»´åº¦çš„ç»Ÿè®¡**ï¼ˆä¸èƒ½åªæœ‰æ€»æ•°ï¼‰
   âœ… **æ¨èä½¿ç”¨ GROUP BY + ç©ºé—´å­—æ®µ**ï¼ˆæŒ‰åŒºåŸŸ/ç­‰çº§åˆ†ç»„ï¼‰
   âœ… **å¿…é¡»åŒ…å«ç©ºé—´ä¿¡æ¯**ï¼ˆä¸­å¿ƒåæ ‡ã€è¾¹ç•ŒèŒƒå›´ç­‰ï¼‰
   âŒ **ç¦æ­¢åªè¿”å›ç®€å•çš„ COUNT(*)**

   **æ­£ç¡®ç¤ºä¾‹1ï¼šæŒ‰è¡Œæ”¿åŒºåˆ†ç»„ç»Ÿè®¡**ï¼ˆâ­ æ¨èï¼Œæœ€å¸¸ç”¨ï¼‰
   ```sql
   -- "æ­¦æ±‰å¸‚æ™¯åŒºçš„ç©ºé—´åˆ†å¸ƒ" â†’ æŒ‰åŒºåŸŸåˆ†ç»„ + ç©ºé—´ä¸­å¿ƒ
   SELECT
     COALESCE(a."æ‰€å±è¡Œæ”¿åŒº", 'æœªçŸ¥') as district,
     COUNT(*) as count,
     AVG(a.lng_wgs84) as center_lng,  -- â­ åŒºåŸŸä¸­å¿ƒç»åº¦
     AVG(a.lat_wgs84) as center_lat   -- â­ åŒºåŸŸä¸­å¿ƒçº¬åº¦
   FROM a_sight a
   WHERE a."æ‰€å±åŸå¸‚" = 'æ­¦æ±‰å¸‚'
     AND a.lng_wgs84 IS NOT NULL
     AND a.lat_wgs84 IS NOT NULL
   GROUP BY a."æ‰€å±è¡Œæ”¿åŒº"
   ORDER BY count DESC
   ```

   **æ­£ç¡®ç¤ºä¾‹2ï¼šæŒ‰æ™¯åŒºç­‰çº§åˆ†ç»„ + ç©ºé—´ä¸­å¿ƒ**
   ```sql
   -- "ç»Ÿè®¡å„ç­‰çº§æ™¯åŒºçš„ç©ºé—´åˆ†å¸ƒ"
   SELECT
     a.level,
     COUNT(*) as count,
     AVG(a.lng_wgs84) as center_lng,
     AVG(a.lat_wgs84) as center_lat
   FROM a_sight a
   WHERE a."æ‰€å±åŸå¸‚" = 'æ­¦æ±‰å¸‚'
     AND a.lng_wgs84 IS NOT NULL
   GROUP BY a.level
   ORDER BY a.level
   ```

   **æ­£ç¡®ç¤ºä¾‹3ï¼šç©ºé—´èŒƒå›´ç»Ÿè®¡**ï¼ˆè¾¹ç•Œæ¡†ï¼‰
   ```sql
   -- "æ­¦æ±‰å¸‚æ™¯åŒºçš„åˆ†å¸ƒèŒƒå›´"
   SELECT
     COUNT(*) as total_count,
     MIN(lng_wgs84) as bbox_min_lng,  -- è¥¿è¾¹ç•Œ
     MAX(lng_wgs84) as bbox_max_lng,  -- ä¸œè¾¹ç•Œ
     MIN(lat_wgs84) as bbox_min_lat,  -- å—è¾¹ç•Œ
     MAX(lat_wgs84) as bbox_max_lat,  -- åŒ—è¾¹ç•Œ
     AVG(lng_wgs84) as center_lng,    -- ä¸­å¿ƒç‚¹ç»åº¦
     AVG(lat_wgs84) as center_lat     -- ä¸­å¿ƒç‚¹çº¬åº¦
   FROM a_sight
   WHERE "æ‰€å±åŸå¸‚" = 'æ­¦æ±‰å¸‚' AND lng_wgs84 IS NOT NULL
   ```

   **æ­£ç¡®ç¤ºä¾‹4ï¼šé«˜çº§ç©ºé—´åˆ†æ**ï¼ˆå¯é€‰ï¼Œä½¿ç”¨ PostGIS å‡½æ•°ï¼‰
   ```sql
   -- åœ°ç†ç½‘æ ¼ç»Ÿè®¡ï¼ˆéœ€è¦ PostGISï¼‰
   SELECT
     ST_GeoHash(lng_wgs84, lat_wgs84, 4) as grid_id,
     COUNT(*) as count,
     AVG(lng_wgs84) as center_lng,
     AVG(lat_wgs84) as center_lat
   FROM a_sight
   WHERE "æ‰€å±åŸå¸‚" = 'æ­¦æ±‰å¸‚'
     AND lng_wgs84 IS NOT NULL
   GROUP BY ST_GeoHash(lng_wgs84, lat_wgs84, 4)
   ORDER BY count DESC
   ```

   âŒ **é”™è¯¯ç¤ºä¾‹**ï¼ˆåªè¿”å›æ€»æ•°ï¼Œä¸¢å¤±ç©ºé—´ç»´åº¦ï¼‰ï¼š
   ```sql
   -- âŒ é”™è¯¯ï¼š"ç©ºé—´åˆ†å¸ƒ"æŸ¥è¯¢ä¸èƒ½åªè¿”å›æ€»æ•°
   SELECT COUNT(*) as count
   FROM a_sight
   WHERE "æ‰€å±åŸå¸‚" = 'æ­¦æ±‰å¸‚'
   ```

### ğŸ“‹ Query æŸ¥è¯¢ (intent_type="query") - è§„åˆ™ï¼š

#### Query + Non-Spatial (æ™®é€šæ•°æ®æŸ¥è¯¢)
   âœ… **å¿…é¡»ä½¿ç”¨ json_agg(json_build_object(...))**
   âœ… **å¿…é¡»è¿”å› JSON æ•°ç»„æ ¼å¼**
   âœ… **å¿…é¡»åŒ…å«å®Œæ•´çš„è®°å½•ä¿¡æ¯**

   **æ­£ç¡®ç¤ºä¾‹**ï¼š
   ```sql
   SELECT json_agg(json_build_object(
       'name', name,
       'level', level,
       'city', city
   )) as result
   FROM a_sight WHERE level = '5A'
   ```

#### Query + Spatial (ç©ºé—´æ•°æ®æŸ¥è¯¢)
   âœ… **å¿…é¡»ä½¿ç”¨ json_agg(json_build_object(...))**
   âœ… **å¿…é¡»åŒ…å«ç©ºé—´åæ ‡ä¿¡æ¯**
   âœ… **åº”è¯¥ä½¿ç”¨ç©ºé—´æ’åºå’Œè¿‡æ»¤**
   âœ… **å¯ä»¥åŒ…å«ç©ºé—´èšç±»åˆ†æ**

   **æ­£ç¡®ç¤ºä¾‹**ï¼š
   ```sql
   -- ç©ºé—´æŸ¥è¯¢ï¼ˆå¸¦åæ ‡ï¼‰
   SELECT json_agg(json_build_object(
       'name', name,
       'level', level,
       'coordinates', json_build_array(lng_wgs84, lat_wgs84)
   )) as result
   FROM a_sight 
   WHERE "æ‰€å±åŸå¸‚" = 'æ­¦æ±‰å¸‚'
     AND lng_wgs84 IS NOT NULL 
     AND lat_wgs84 IS NOT NULL

   -- ç©ºé—´èšç±»æŸ¥è¯¢
   SELECT json_agg(json_build_object(
       'name', name,
       'level', level,
       'coordinates', json_build_array(lng_wgs84, lat_wgs84),
       'cluster_id', ST_GeoHash(lng_wgs84, lat_wgs84, 3)
   )) as result
   FROM a_sight 
   WHERE "æ‰€å±åŸå¸‚" = 'æ­¦æ±‰å¸‚'
   ORDER BY ST_GeoHash(lng_wgs84, lat_wgs84, 3)
   ```

---

## ğŸ¤” è¯·è¿ç”¨ä½ çš„ SQL ä¸“ä¸šçŸ¥è¯†

åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œè¯·æ€è€ƒï¼š

### 1. æŸ¥è¯¢æ„å›¾ç†è§£
   - ç”¨æˆ·çœŸæ­£éœ€è¦ä»€ä¹ˆæ•°æ®ï¼Ÿ
   - æ˜¯éœ€è¦ç»Ÿè®¡æ±‡æ€»ï¼ˆæ•°é‡ã€å¹³å‡å€¼ç­‰ï¼‰ï¼Œè¿˜æ˜¯å…·ä½“è®°å½•åˆ—è¡¨ï¼Ÿ
   - æ˜¯å¦æ¶‰åŠç©ºé—´è®¡ç®—ï¼ˆè·ç¦»ã€èŒƒå›´ç­‰ï¼‰ï¼Ÿ

   ğŸ’¡ **å…³é”®åŒºåˆ†**ï¼š
   - **intent_type = "summary"**: ç”¨æˆ·åªéœ€è¦ç»Ÿè®¡æ•°å­—ï¼ˆæ•°é‡ã€å¹³å‡å€¼ã€æ€»æ•°ã€åˆ†å¸ƒç­‰ï¼‰ï¼Œä¸éœ€è¦è¯¦ç»†è®°å½•
   - **intent_type = "query"**: ç”¨æˆ·éœ€è¦å…·ä½“è®°å½•åˆ—è¡¨æˆ–è¯¦ç»†ä¿¡æ¯

### 2. æ•°æ®è·å–ç­–ç•¥
   - éœ€è¦ä»å“ªäº›è¡¨è·å–æ•°æ®ï¼Ÿï¼ˆå‚è€ƒä¸Šæ–¹Schemaä¿¡æ¯ä¸­çš„è¡¨ç»“æ„ï¼‰
   - å¦‚ä½•ç¡®ä¿è·å–å®Œæ•´çš„æ•°æ®ï¼ˆåŒ…æ‹¬åªåœ¨æŸä¸ªè¡¨ä¸­å­˜åœ¨çš„è®°å½•ï¼‰ï¼Ÿ
   - æ˜¯å¦éœ€è¦è¡¨è¿æ¥ï¼Ÿç”¨ä»€ä¹ˆè¿æ¥æ–¹å¼æœ€åˆé€‚ï¼ˆINNER JOINã€LEFT JOINã€UNION ALLç­‰ï¼‰ï¼Ÿ
   - å¯¹äºä¸¤è¡¨æ•°æ®åªæœ‰éƒ¨åˆ†é‡åˆçš„æƒ…å†µï¼Œå¦‚ä½•è®¾è®¡æŸ¥è¯¢æ‰ä¸ä¼šé—æ¼æ•°æ®ï¼Ÿ

### 3. SQL ç»“æ„è®¾è®¡

   **Summary æŸ¥è¯¢**ï¼ˆintent_type="summary"ï¼‰ï¼š
   - âœ… ç›´æ¥ä½¿ç”¨èšåˆå‡½æ•°ï¼šCOUNTã€SUMã€AVGã€MAXã€MIN ç­‰
   - âœ… è¿”å›ç®€å•çš„æ•°å€¼æˆ–ç»Ÿè®¡ç»“æœ
   - âŒ **ä¸è¦ä½¿ç”¨ json_agg æˆ– json_build_object**
   - ç¤ºä¾‹ï¼š`SELECT COUNT(*) as count FROM table WHERE condition`
   - ç¤ºä¾‹ï¼š`SELECT level, COUNT(*) as count FROM table GROUP BY level`

   **Query æŸ¥è¯¢**ï¼ˆintent_type="query"ï¼‰ï¼š
   - âœ… ä½¿ç”¨ json_agg(json_build_object(...)) è¿”å› JSON æ•°ç»„
   - âœ… è¿”å›å®Œæ•´çš„è®°å½•åˆ—è¡¨
   - ç¤ºä¾‹ï¼š`SELECT json_agg(json_build_object(...)) as result FROM table WHERE condition`

   **å…¶ä»–æ³¨æ„äº‹é¡¹**ï¼š
   - WHERE æ¡ä»¶åº”è¯¥æ”¾åœ¨å“ªé‡Œï¼Ÿï¼ˆå­æŸ¥è¯¢å†…éƒ¨ã€å¤–å±‚ã€è¿˜æ˜¯ä¸¤è€…éƒ½æœ‰ï¼‰
   - å¦‚ä½•å¤„ç†å¯èƒ½çš„ NULL å€¼å’Œæ•°æ®ç±»å‹é—®é¢˜ï¼Ÿï¼ˆå‚è€ƒSchemaä¸­çš„å­—æ®µç±»å‹ï¼‰
   - å¦‚ä½•é¿å…è¡¨åˆ«åä½œç”¨åŸŸé”™è¯¯ï¼ˆå­æŸ¥è¯¢å†…çš„åˆ«åå¤–å±‚æ— æ³•è®¿é—®ï¼‰ï¼Ÿ

### 4. æ€§èƒ½å’Œæ­£ç¡®æ€§
   - SQL è¯­æ³•æ˜¯å¦å®Œæ•´ï¼ˆFROM å­å¥ã€è¡¨åˆ«åå®šä¹‰ç­‰ï¼‰ï¼Ÿ
   - æ˜¯å¦è€ƒè™‘äº†æŸ¥è¯¢æ€§èƒ½ï¼ˆLIMITã€ç´¢å¼•åˆ©ç”¨ç­‰ï¼‰ï¼Ÿ
   - å¯¹äºèšåˆæŸ¥è¯¢ï¼Œæ˜¯å¦éµå®ˆäº† GROUP BY è§„åˆ™ï¼Ÿ

---

è¯·åŸºäºä½ çš„ä¸“ä¸šåˆ¤æ–­å’Œ PostgreSQL æœ€ä½³å®è·µï¼Œç”Ÿæˆæœ€ä¼˜çš„ SQL æŸ¥è¯¢ã€‚

åªè¿”å›SQLè¯­å¥ï¼Œä¸è¦è§£é‡Šã€‚

SQL:"""
        self.sql_generation_inputs = [
            "base_prompt",
            "database_schema",
            "query",
            "intent_type",
            "is_spatial",
            "spatial_type",
            "confidence",
            "keywords_matched",
        ]

        # âœ… å¯å‘å¼è¡¥å……æŸ¥è¯¢ Promptï¼ˆå¼•å¯¼ LLM æ€è€ƒå¦‚ä½•è·å–å®Œæ•´æ•°æ®ï¼‰
        self.followup_query_template = """ä½ æ˜¯ä¸€ä¸ªæ“…é•¿ä¼˜åŒ–å’Œè¡¥å……æŸ¥è¯¢çš„ SQL ä¸“å®¶ã€‚

{base_prompt}

**æ•°æ®åº“Schemaä¿¡æ¯**ï¼ˆå®Œæ•´å­—æ®µç±»å‹ä¾›ä½ å‚è€ƒï¼‰:
{database_schema}

**ç”¨æˆ·åŸå§‹éœ€æ±‚**: {original_query}

**å·²æ‰§è¡Œçš„æŸ¥è¯¢**:
```sql
{previous_sql}
```

**å½“å‰æ•°æ®çŠ¶å†µ**:
- å·²è·å–è®°å½•æ•°: {record_count}
- å‘ç°ç¼ºå¤±å­—æ®µ: {missing_fields}

---

{match_rules}

## ğŸ¤” è¯·åˆ†æå¹¶å†³å®šå¦‚ä½•è·å–å®Œæ•´æ•°æ®

### æ€è€ƒæ¡†æ¶ï¼š

1. **æ•°æ®å®Œæ•´æ€§åˆ†æ**
   - å“ªäº›å­—æ®µç¼ºå¤±äº†ï¼Ÿ
   - è¿™äº›å­—æ®µé€šå¸¸åœ¨å“ªä¸ªè¡¨ä¸­ï¼Ÿï¼ˆå‚è€ƒä¸Šæ–¹Schemaä¿¡æ¯ä¸­çš„è¡¨ç»“æ„å’Œå­—æ®µç±»å‹ï¼‰
   - æ˜¯å¦å¯ä»¥é€šè¿‡è¡¥å……æŸ¥è¯¢è·å–ï¼Ÿè¿˜æ˜¯æ•°æ®æºæœ¬èº«ä¸å®Œæ•´ï¼Ÿ

2. **è¡¥å……æŸ¥è¯¢ç­–ç•¥**
   - åº”è¯¥æŸ¥è¯¢å“ªäº›è¡¨ï¼Ÿ
   - å¦‚ä½•ä¸å·²æœ‰æ•°æ®å…³è”ï¼Ÿï¼ˆé€šè¿‡åç§°åŒ¹é…ã€ID å…³è”ç­‰ï¼‰
   - ç”¨ä»€ä¹ˆè¿æ¥æ–¹å¼æœ€åˆé€‚ï¼Ÿï¼ˆLEFT JOINã€INNER JOINã€è¿˜æ˜¯å…¶ä»–ï¼‰

3. **æŸ¥è¯¢ä¼˜åŒ–**
   - å¦‚ä½•é¿å…é‡å¤è·å–å·²æœ‰æ•°æ®ï¼Ÿ
   - å¦‚ä½•ç¡®ä¿è¡¥å……æŸ¥è¯¢çš„æ•ˆç‡ï¼Ÿ
   - WHERE æ¡ä»¶åº”è¯¥å¦‚ä½•è®¾ç½®ä»¥ç²¾å‡†è·å–ç¼ºå¤±æ•°æ®ï¼Ÿ

4. **SQL ç»“æ„è®¾è®¡**
   - æ˜¯å¦ä½¿ç”¨ json_agg è¿”å› JSON æ•°ç»„ï¼Ÿ
   - å¦‚ä½•ç¡®ä¿è¿”å›çš„æ•°æ®å¯ä»¥ä¸å·²æœ‰æ•°æ®åˆå¹¶ï¼Ÿ
   - å¦‚ä½•å¤„ç†å¯èƒ½çš„ NULL å€¼ï¼Ÿï¼ˆå‚è€ƒSchemaä¸­çš„å­—æ®µç±»å‹ï¼‰

---

è¯·åŸºäºä½ çš„ SQL ä¸“ä¸šçŸ¥è¯†ï¼Œç”Ÿæˆè¡¥å……æŸ¥è¯¢çš„ SQL è¯­å¥ã€‚

åªè¿”å›SQLè¯­å¥ï¼Œä¸è¦è§£é‡Šã€‚

SQL:"""
        self.followup_query_inputs = [
            "base_prompt",
            "database_schema",
            "original_query",
            "previous_sql",
            "record_count",
            "missing_fields",
        ]

    def set_database_schema(self, formatted_schema: Optional[str]):
        """ç¼“å­˜æ•°æ®åº“schemaï¼Œé¿å…æ¯æ¬¡è°ƒç”¨æ—¶é‡å¤ä¼ å…¥"""
        if formatted_schema and formatted_schema.strip():
            cleaned_schema = formatted_schema.strip()
            if cleaned_schema != self._cached_schema:
                self._cached_schema = cleaned_schema
                self.logger.info("âœ… SQLGenerator schema context updated (length=%s)", len(cleaned_schema))
        else:
            self.logger.debug("set_database_schema called with empty schema; ignoring")

    def _resolve_schema_for_prompt(self, database_schema: Optional[str] = None) -> str:
        """ä¼˜å…ˆä½¿ç”¨ä¼ å…¥schemaï¼Œå¦åˆ™ä½¿ç”¨ç¼“å­˜æˆ–LLMä¸Šä¸‹æ–‡"""
        candidates = [
            database_schema,
            self._cached_schema,
        ]

        if hasattr(self.llm, 'system_context'):
            context_schema = getattr(self.llm, 'system_context', {}).get('database_schema')
        else:
            context_schema = None
        candidates.append(context_schema)

        for schema in candidates:
            if isinstance(schema, str) and schema.strip():
                return schema
        return "(Schemaä¿¡æ¯æœªåŠ è½½)"

    def generate_initial_sql(
        self,
        query: str,
        intent_info: Optional[Dict[str, Any]] = None,  # âœ… æ„å›¾ä¿¡æ¯
        database_schema: Optional[str] = None,  # âœ… æ–°å¢å‚æ•°ï¼šæ•°æ®åº“Schema
        match_mode: str = "fuzzy",
    ) -> str:
        """
        ç”Ÿæˆåˆå§‹SQLæŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            intent_info: æŸ¥è¯¢æ„å›¾ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                - intent_type: "query" æˆ– "summary"
                - is_spatial: bool
                - confidence: float
                - keywords_matched: List[str]
            database_schema: æ ¼å¼åŒ–çš„æ•°æ®åº“Schemaå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼‰
            match_mode: åŒ¹é…æ¨¡å¼ï¼ˆfuzzy/ exactï¼‰ï¼Œé»˜è®¤ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…

        Returns:
            ç”Ÿæˆçš„SQLè¯­å¥
        """
        try:
            # âœ… æå–æ„å›¾ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
            intent_type = "query"  # é»˜è®¤å€¼
            is_spatial = False
            confidence = 0.0
            keywords_matched = []

            if intent_info:
                intent_type = intent_info.get("intent_type", "query")
                is_spatial = intent_info.get("is_spatial", False)
                confidence = intent_info.get("confidence", 0.0)
                keywords_matched = intent_info.get("keywords_matched", [])

            # æ ¼å¼åŒ–å…³é”®è¯åˆ—è¡¨
            keywords_str = ", ".join(keywords_matched) if keywords_matched else "æ— "

            # âœ… æ ¼å¼åŒ–ç©ºé—´ç±»å‹æ–‡æœ¬
            spatial_type = "ç©ºé—´" if is_spatial else "éç©ºé—´"

            # âœ… å¦‚æœæ²¡æœ‰æä¾›schemaï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            schema_str = self._resolve_schema_for_prompt(database_schema)

            # æ„å»ºæç¤ºè¯ï¼ˆâœ… ä¼ é€’æ„å›¾ä¿¡æ¯å’ŒSchemaï¼‰
            generation_prompt = self._build_sql_generation_prompt(match_mode)
            prompt_text = generation_prompt.format(
                base_prompt=self.base_prompt,
                database_schema=schema_str,
                query=query,
                intent_type=intent_type,
                is_spatial=is_spatial,
                spatial_type=spatial_type,  # âœ… æ–°å¢å‚æ•°
                confidence=f"{confidence:.2f}",
                keywords_matched=keywords_str
            )

            # è°ƒç”¨LLMç”ŸæˆSQL
            self.logger.debug(
                f"Generating initial SQL for query: {query} "
                f"(intent={intent_type}, spatial={is_spatial}, confidence={confidence:.2f}, match_mode={match_mode})"
            )
            response = self.llm.llm.invoke(prompt_text)

            # æå–SQL
            sql = self._extract_sql(response)

            # âœ… éªŒè¯SQLç»“æ„
            if not self._validate_sql_structure(sql):
                self.logger.warning("Generated SQL missing proper FROM clause, attempting to fix")
                sql = self._add_from_clause_if_missing(sql, query)
                # å†æ¬¡éªŒè¯
                if not self._validate_sql_structure(sql):
                    self.logger.error("Unable to fix SQL structure automatically")

            # âœ… éªŒè¯ summary æŸ¥è¯¢çš„ SQL
            is_valid, warning = self._validate_summary_sql(sql, intent_type, is_spatial)
            if not is_valid:
                self.logger.warning(f"Summary SQL validation failed: {warning}")
                self.logger.info(f"Generated SQL (may be incorrect for summary): {sql[:100]}...")

                # âœ… å°è¯•è‡ªåŠ¨ä¿®å¤
                sql = self._fix_summary_sql_if_needed(sql, intent_type)

                # âœ… å†æ¬¡éªŒè¯ä¿®å¤åçš„ SQL
                is_valid_after_fix, warning_after_fix = self._validate_summary_sql(sql, intent_type, is_spatial)
                if is_valid_after_fix:
                    self.logger.info("âœ“ Summary SQL auto-fixed successfully")
                else:
                    self.logger.error(f"âœ— Summary SQL fix failed: {warning_after_fix}")
                    # ä¿®å¤å¤±è´¥ï¼Œä½†ä»è¿”å›ï¼ˆè®©åç»­é”™è¯¯å¤„ç†æœºåˆ¶å¤„ç†ï¼‰

            self.logger.info(f"Generated initial SQL ({intent_type}, spatial={is_spatial}): {sql[:100]}...")
            return sql

        except Exception as e:
            self.logger.error(f"Initial SQL generation failed: {e}")
            raise

    def generate_followup_sql(
        self,
        original_query: str,
        previous_sql: str,
        record_count: int,
        missing_fields: Optional[List[str]] = None,
        database_schema: Optional[str] = None,  # âœ… æ–°å¢å‚æ•°ï¼šæ•°æ®åº“Schema
        match_mode: str = "fuzzy",
    ) -> str:
        """
        ç”Ÿæˆåç»­è¡¥å……æŸ¥è¯¢SQL

        Args:
            original_query: åŸå§‹æŸ¥è¯¢
            previous_sql: ä¹‹å‰æ‰§è¡Œçš„SQL
            record_count: å½“å‰è®°å½•æ•°
            missing_fields: ç¼ºå¤±çš„å­—æ®µåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            database_schema: æ ¼å¼åŒ–çš„æ•°æ®åº“Schemaå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼‰
            match_mode: åŒ¹é…æ¨¡å¼ï¼ˆfuzzy/ exactï¼‰

        Returns:
            ç”Ÿæˆçš„è¡¥å……SQLè¯­å¥
        """
        try:
            # âœ… å¦‚æœæ²¡æœ‰æä¾›schemaï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            schema_str = self._resolve_schema_for_prompt(database_schema)
            missing_fields = missing_fields or []

            # æ„å»ºæç¤ºè¯ï¼ˆåŒ…å«Schemaï¼‰
            followup_prompt = self._build_followup_prompt(match_mode)
            prompt_text = followup_prompt.format(
                base_prompt=self.base_prompt,
                database_schema=schema_str,
                original_query=original_query,
                previous_sql=previous_sql,
                record_count=record_count,
                missing_fields=", ".join(missing_fields or [])
            )

            # è°ƒç”¨LLMç”ŸæˆSQL
            self.logger.debug(
                f"Generating followup SQL; previous count={record_count}, missing fields={missing_fields or []}, match_mode={match_mode}"
            )
            response = self.llm.llm.invoke(prompt_text)

            # æå–SQL
            sql = self._extract_sql(response)
            self.logger.info(f"Generated followup SQL: {sql[:100]}...")
            return sql

        except Exception as e:
            self.logger.error(f"Followup SQL generation failed: {e}")
            raise

    def analyze_missing_info(
        self,
        query: str,
        current_data: Optional[List[Dict[str, Any]]]
    ) -> Dict[str, Any]:
        """
        ä¿ç•™å…¼å®¹æ¥å£ï¼Œç›´æ¥è¿”å›ç»Ÿä¸€ç»“æ„ï¼Œé¿å…é‡å¤å­—æ®µåˆ†æã€‚
        """
        if not current_data:
            return {
                "has_missing": True,
                "missing_fields": [],
                "data_complete": False,
                "suggestion": "æš‚æ— æ•°æ®ï¼Œå¯æŒ‰éœ€é‡æ–°æŸ¥è¯¢"
            }

        self.logger.debug("Skipping missing-field analysis; assume full column set returned")
        return {
            "has_missing": False,
            "missing_fields": [],
            "data_complete": True,
            "suggestion": "ç»“æœå·²åŒ…å«å…¨éƒ¨å­—æ®µï¼Œå¯ç›´æ¥ç”Ÿæˆç­”æ¡ˆ"
        }

    def _extract_sql(self, response) -> str:
        """
        ä»LLMå“åº”ä¸­æå–SQLè¯­å¥

        Args:
            response: LLMå“åº”

        Returns:
            æ¸…ç†åçš„SQLè¯­å¥
        """
        # æå–SQLï¼ˆresponseå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡ï¼‰
        if hasattr(response, 'content'):
            sql = response.content.strip()
        else:
            sql = str(response).strip()

        # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
        sql = re.sub(r'^```sql\s*', '', sql, flags=re.IGNORECASE)
        sql = re.sub(r'^```\s*', '', sql)
        sql = re.sub(r'\s*```$', '', sql)
        sql = sql.strip()

        return sql

    def fix_sql_with_error(
        self,
        sql: str,
        error: str,
        query: str,
        database_schema: Optional[str] = None  # âœ… æ–°å¢å‚æ•°ï¼šæ•°æ®åº“Schema
    ) -> str:
        """
        æ ¹æ®é”™è¯¯ä¿¡æ¯ä¿®å¤SQL

        Args:
            sql: åŸå§‹SQL
            error: é”™è¯¯ä¿¡æ¯
            query: åŸå§‹æŸ¥è¯¢
            database_schema: æ ¼å¼åŒ–çš„æ•°æ®åº“Schemaå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¿®å¤åçš„SQL
        """
        try:
            # âœ… å¦‚æœæ²¡æœ‰æä¾›schemaï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            schema_str = self._resolve_schema_for_prompt(database_schema)

            # âœ… å¯å‘å¼ä¿®å¤æç¤ºè¯ï¼ˆè°ƒåŠ¨ LLM çš„ SQL ä¸“ä¸šçŸ¥è¯†ï¼‰
            fix_prompt = f"""ä½ æ˜¯ä¸€ä¸ªç²¾é€š PostgreSQL å’Œ PostGIS çš„ SQL ä¸“å®¶ã€‚

**æ•°æ®åº“Schemaä¿¡æ¯**ï¼ˆå®Œæ•´å­—æ®µç±»å‹ä¾›ä½ å‚è€ƒï¼‰:
{schema_str}

**ç”¨æˆ·éœ€æ±‚**: {query}

**ç”Ÿæˆçš„ SQL**:
```sql
{sql}
```

**æ‰§è¡Œé”™è¯¯**:
```
{error}
```

---

## ğŸ¤” è¯·è¿ç”¨ä½ çš„ PostgreSQL ä¸“ä¸šçŸ¥è¯†è¿›è¡Œè¯Šæ–­å’Œä¿®å¤

### æ€è€ƒæ¡†æ¶ï¼š

1. **é”™è¯¯è¯Šæ–­**
   - è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„ PostgreSQL é”™è¯¯ï¼Ÿï¼ˆè¯­æ³•ã€çº¦æŸã€èšåˆã€ç±»å‹è½¬æ¢ã€ä½œç”¨åŸŸç­‰ï¼‰
   - é”™è¯¯çš„æ ¹æœ¬åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ
   - SQL çš„å“ªä¸ªéƒ¨åˆ†è¿åäº† PostgreSQL è§„åˆ™ï¼Ÿ

2. **é—®é¢˜åˆ†æ**
   - æŸ¥è¯¢çš„æ„å›¾æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆè·å–æ•°æ®ã€ç»Ÿè®¡ã€ç©ºé—´æŸ¥è¯¢ï¼‰
   - å½“å‰çš„ SQL ç»“æ„æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ
   - å“ªäº› PostgreSQL ç‰¹æ€§æˆ–è§„åˆ™ä¸æ­¤ç›¸å…³ï¼Ÿ
   - å‚è€ƒä¸Šæ–¹Schemaä¿¡æ¯ï¼Œå­—æ®µç±»å‹æ˜¯å¦æ­£ç¡®ä½¿ç”¨ï¼Ÿ

3. **ä¿®å¤ç­–ç•¥**
   - å¦‚ä½•åœ¨ä¿æŒæŸ¥è¯¢æ„å›¾çš„åŒæ—¶ä¿®å¤é”™è¯¯ï¼Ÿ
   - æ˜¯å¦éœ€è¦è°ƒæ•´ï¼šè¡¨è¿æ¥æ–¹å¼ã€WHERE ä½ç½®ã€èšåˆå‡½æ•°ã€å­æŸ¥è¯¢ç»“æ„ã€å­—æ®µä½œç”¨åŸŸï¼Ÿ
   - æœ‰æ²¡æœ‰æ›´ä¼˜é›…çš„ PostgreSQL è§£å†³æ–¹æ¡ˆï¼Ÿ

4. **æœ€ä½³å®è·µ**
   - ä¿®å¤åçš„ SQL æ˜¯å¦ç¬¦åˆ PostgreSQL è¯­æ³•è§„èŒƒï¼Ÿ
   - æ˜¯å¦è€ƒè™‘äº†æ€§èƒ½ä¼˜åŒ–ï¼Ÿ
   - æ˜¯å¦å¤„ç†äº†å¯èƒ½çš„ NULL å€¼å’Œè¾¹ç•Œæƒ…å†µï¼Ÿï¼ˆå‚è€ƒSchemaä¸­çš„å­—æ®µç±»å‹ï¼‰

---

## ğŸ“š ç›¸å…³èƒŒæ™¯çŸ¥è¯†ï¼ˆä¾›å‚è€ƒï¼‰

**PostgreSQL æ ¸å¿ƒè§„åˆ™**:
- èšåˆæŸ¥è¯¢æ—¶ï¼ŒSELECT/WHERE/HAVING ä¸­å¼•ç”¨çš„éèšåˆå­—æ®µå¿…é¡»åœ¨ GROUP BY ä¸­
- å­æŸ¥è¯¢çš„è¡¨åˆ«åï¼ˆå¦‚ a, tï¼‰ä½œç”¨åŸŸä»…é™äºè¯¥å­æŸ¥è¯¢å†…éƒ¨ï¼Œå¤–å±‚æ— æ³•ç›´æ¥è®¿é—®
- UNION ALL è¦æ±‚å„å­æŸ¥è¯¢è¿”å›ç›¸åŒæ•°é‡ã€é¡ºåºå’Œç±»å‹çš„å­—æ®µ
- FROM å­å¥å¿…é¡»å…ˆå®šä¹‰è¡¨å’Œåˆ«åï¼Œæ‰èƒ½åœ¨ SELECT/WHERE ä¸­ä½¿ç”¨

---

è¯·åŸºäºä½ çš„ SQL ä¸“ä¸šçŸ¥è¯†å’Œå¯¹é”™è¯¯çš„ç†è§£ï¼Œç”Ÿæˆä¿®å¤åçš„ SQL è¯­å¥ã€‚

åªè¿”å›ä¿®å¤åçš„ SQLï¼Œä¸è¦è§£é‡Šã€‚

ä¿®å¤åçš„ SQL:"""

            # è°ƒç”¨LLMç”Ÿæˆä¿®å¤åçš„SQL
            self.logger.debug(f"Attempting to fix SQL with error: {error[:100]}")
            response = self.llm.llm.invoke(fix_prompt)

            # æå–ä¿®å¤åçš„SQL
            fixed_sql = self._extract_sql(response)

            # âœ… éªŒè¯ä¿®å¤åçš„SQLæ˜¯å¦åŒ…å«FROMå­å¥
            if not self._validate_sql_structure(fixed_sql):
                self.logger.warning("Fixed SQL still missing FROM clause, adding it manually")
                fixed_sql = self._add_from_clause_if_missing(fixed_sql, query)

            self.logger.info(f"SQL fixed: {fixed_sql[:100]}...")
            return fixed_sql

        except Exception as e:
            self.logger.error(f"Failed to fix SQL: {e}")
            # å¦‚æœä¿®å¤å¤±è´¥ï¼Œè¿”å›åŸå§‹SQL
            return sql

    def regenerate_with_feedback(
        self,
        query: str,
        previous_sql: str,
        feedback: str,
        intent_info: Optional[Dict[str, Any]] = None,
        database_schema: Optional[str] = None
    ) -> str:
        """
        åŸºäºéªŒè¯åé¦ˆé‡æ–°ç”Ÿæˆæ”¹è¿›çš„ SQL

        Args:
            query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            previous_sql: ä¹‹å‰ç”Ÿæˆçš„ SQL
            feedback: éªŒè¯åé¦ˆä¿¡æ¯ï¼ˆåŒ…å«é—®é¢˜å’Œå»ºè®®ï¼‰
            intent_info: æŸ¥è¯¢æ„å›¾ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            database_schema: æ ¼å¼åŒ–çš„æ•°æ®åº“Schemaå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼‰

        Returns:
            str: æ”¹è¿›åçš„ SQL
        """
        try:
            # å¦‚æœæ²¡æœ‰æä¾›schemaï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            schema_str = self._resolve_schema_for_prompt(database_schema)

            # è·å–æ„å›¾ä¿¡æ¯
            intent_type = intent_info.get("intent_type", "query") if intent_info else "query"
            is_spatial = intent_info.get("is_spatial", False) if intent_info else False

            # æ„å»ºæ”¹è¿›æç¤ºè¯
            improve_prompt = f"""ä½ æ˜¯ PostgreSQL + PostGIS ä¸“å®¶ï¼Œéœ€è¦åŸºäºéªŒè¯åé¦ˆæ”¹è¿› SQL æŸ¥è¯¢ã€‚

**æ•°æ®åº“Schemaä¿¡æ¯**:
{schema_str}

**ç”¨æˆ·é—®é¢˜**: {query}

**æŸ¥è¯¢æ„å›¾**: {intent_type} (ç©ºé—´æŸ¥è¯¢: {'æ˜¯' if is_spatial else 'å¦'})

**ä¹‹å‰çš„ SQL**:
```sql
{previous_sql}
```

**éªŒè¯åé¦ˆ**:
{feedback}

---

## ğŸ¯ ä»»åŠ¡

è¯·æ ¹æ®éªŒè¯åé¦ˆä¸­æŒ‡å‡ºçš„é—®é¢˜ï¼Œæ”¹è¿› SQL æŸ¥è¯¢ä»¥æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚

## ğŸ” æ”¹è¿›æ–¹å‘

1. **åˆ†æåé¦ˆ**:
   - åé¦ˆæŒ‡å‡ºäº†ä»€ä¹ˆé—®é¢˜ï¼Ÿï¼ˆç¼ºå°‘å­—æ®µã€æ•°æ®ä¸å‡†ç¡®ã€ä¸ç›¸å…³ç­‰ï¼‰
   - é—®é¢˜çš„æ ¹æœ¬åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ
   - ç”¨æˆ·å®é™…éœ€è¦ä»€ä¹ˆä¿¡æ¯ï¼Ÿ

2. **æ”¹è¿›ç­–ç•¥**:
   - å¦‚æœç¼ºå°‘å…³é”®å­—æ®µï¼šæ·»åŠ å¿…è¦çš„å­—æ®µåˆ° SELECT å­å¥
   - å¦‚æœéœ€è¦åæ ‡ä¿¡æ¯ï¼šç¡®ä¿åŒ…å« ST_X(geom) as longitude, ST_Y(geom) as latitude
   - å¦‚æœæ•°æ®ä¸å‡†ç¡®ï¼šæ£€æŸ¥ WHERE æ¡ä»¶å’Œ JOIN å…³ç³»
   - å¦‚æœç»“æœä¸ç›¸å…³ï¼šé‡æ–°å®¡è§†æŸ¥è¯¢é€»è¾‘

3. **æ•°æ®åº“Schemaåº”ç”¨**:
   - å‚è€ƒä¸Šæ–¹Schemaä¿¡æ¯ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è¡¨åå’Œå­—æ®µå
   - æ³¨æ„å­—æ®µç±»å‹ï¼ˆå¦‚ geometry ç±»å‹éœ€ç”¨ PostGIS å‡½æ•°ï¼‰
   - è€ƒè™‘è¡¨ä¹‹é—´çš„å…³è”å…³ç³»

4. **æŸ¥è¯¢æ„å›¾è€ƒè™‘**:
   - å¦‚æœæ˜¯ summary ç±»å‹ï¼šç¡®ä¿åŒ…å«èšåˆå‡½æ•°ï¼ˆCOUNT, SUM, AVGç­‰ï¼‰å’Œ GROUP BY
   - å¦‚æœæ˜¯ query ç±»å‹ï¼šç¡®ä¿è¿”å›å®Œæ•´çš„è®°å½•åˆ—è¡¨
   - å¦‚æœæ˜¯ç©ºé—´æŸ¥è¯¢ï¼šç¡®ä¿åŒ…å«åæ ‡å­—æ®µå’Œç©ºé—´å‡½æ•°

## âš ï¸ é‡è¦çº¦æŸ

- å¿…é¡»ä¿ç•™ `json_agg(...) as result` çš„è¾“å‡ºæ ¼å¼
- ç¡®ä¿åŒ…å«å®Œæ•´çš„ FROM å­å¥
- ä½¿ç”¨åˆé€‚çš„è¡¨åˆ«åï¼ˆa_sight â†’ a, tourist_spot â†’ tï¼‰
- æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„ JOIN ç±»å‹ï¼ˆFULL OUTER JOIN / LEFT JOINï¼‰

## è¾“å‡º

åªè¿”å›æ”¹è¿›åçš„ SQLï¼Œä¸è¦è§£é‡Šã€‚

æ”¹è¿›åçš„ SQL:"""

            # è°ƒç”¨LLMç”Ÿæˆæ”¹è¿›çš„SQL
            self.logger.debug(f"Regenerating SQL based on feedback: {feedback[:100]}")
            response = self.llm.llm.invoke(improve_prompt)

            # æå–æ”¹è¿›åçš„SQL
            improved_sql = self._extract_sql(response)

            # éªŒè¯æ”¹è¿›åçš„SQLæ˜¯å¦åŒ…å«FROMå­å¥
            if not self._validate_sql_structure(improved_sql):
                self.logger.warning("Improved SQL still missing FROM clause, adding it manually")
                improved_sql = self._add_from_clause_if_missing(improved_sql, query)

            self.logger.info(f"SQL improved based on feedback: {improved_sql[:100]}...")
            return improved_sql

        except Exception as e:
            self.logger.error(f"Failed to regenerate SQL with feedback: {e}")
            # å¦‚æœé‡æ–°ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸå§‹SQL
            return previous_sql

    def _validate_sql_structure(self, sql: str) -> bool:
        """
        éªŒè¯SQLæ˜¯å¦åŒ…å«å¿…éœ€çš„FROMå­å¥å’Œæ­£ç¡®çš„åˆ«åå®šä¹‰

        Args:
            sql: SQLè¯­å¥

        Returns:
            bool: SQLç»“æ„æ˜¯å¦æœ‰æ•ˆ
        """
        sql_lower = sql.lower()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«FROMå…³é”®å­—
        if 'from' not in sql_lower:
            self.logger.warning("SQL missing FROM keyword")
            return False

        # æå–æ‰€æœ‰ä½¿ç”¨çš„è¡¨åˆ«åï¼ˆæ¨¡å¼ï¼šåˆ«å.å­—æ®µåï¼‰
        alias_pattern = r'\b([a-z_][a-z0-9_]*)\.\w+'
        used_aliases = set(re.findall(alias_pattern, sql_lower))
        
        # ç§»é™¤ç³»ç»Ÿå…³é”®å­—å’Œå¸¸è§å‡½æ•°å
        system_keywords = {'select', 'from', 'where', 'group', 'order', 'having', 'limit', 'offset', 'join', 'on', 'as', 'and', 'or', 'not', 'in', 'is', 'null', 'true', 'false'}
        used_aliases = used_aliases - system_keywords

        if not used_aliases:
            # å¦‚æœæ²¡æœ‰ä½¿ç”¨ä»»ä½•åˆ«åï¼Œåˆ™åªéœ€æ£€æŸ¥FROMå­å¥å­˜åœ¨å³å¯
            self.logger.debug("No table aliases used in SQL")
            return True

        # æå–FROMå­å¥ä¸­å®šä¹‰çš„åˆ«å
        from_pattern = r'from\s+(\w+(?:\s+(?:as\s+)?(\w+))?(?:\s*,\s*\w+(?:\s+(?:as\s+)?(\w+))?)*)'
        from_match = re.search(from_pattern, sql_lower)
        
        if not from_match:
            self.logger.warning("FROM clause found but cannot parse table aliases")
            return False

        # æå–æ‰€æœ‰å®šä¹‰çš„åˆ«å
        defined_aliases = set()
        
        # åŒ¹é…ç®€å•çš„è¡¨å®šä¹‰ï¼štable alias æˆ– table AS alias
        simple_table_pattern = r'(\w+)(?:\s+(?:as\s+)?(\w+))?'
        from_content = from_match.group(1)
        
        # åˆ†å‰²å¤šä¸ªè¡¨å®šä¹‰ï¼ˆå¤„ç†é€—å·åˆ†éš”ï¼‰
        table_definitions = re.split(r'\s*,\s*', from_content)
        
        for table_def in table_definitions:
            table_match = re.match(simple_table_pattern, table_def.strip())
            if table_match:
                table_name = table_match.group(1)
                alias_name = table_match.group(2)
                
                # å¦‚æœæ²¡æœ‰æ˜¾å¼åˆ«åï¼Œè¡¨åæœ¬èº«å°±æ˜¯åˆ«å
                if alias_name:
                    defined_aliases.add(alias_name)
                else:
                    defined_aliases.add(table_name)

        # æ£€æŸ¥JOINå­å¥ä¸­çš„åˆ«åå®šä¹‰
        join_pattern = r'(?:inner|left|right|full|cross)\s+join\s+(\w+)(?:\s+(?:as\s+)?(\w+))?'
        join_matches = re.finditer(join_pattern, sql_lower)
        
        for join_match in join_matches:
            table_name = join_match.group(1)
            alias_name = join_match.group(2)
            
            if alias_name:
                defined_aliases.add(alias_name)
            else:
                defined_aliases.add(table_name)

        # æ£€æŸ¥æ‰€æœ‰ä½¿ç”¨çš„åˆ«åæ˜¯å¦éƒ½å·²å®šä¹‰
        undefined_aliases = used_aliases - defined_aliases
        
        if undefined_aliases:
            self.logger.warning(f"SQL uses undefined table aliases: {undefined_aliases}")
            for alias in undefined_aliases:
                self.logger.warning(f"  - Alias '{alias}' is used but not defined in FROM clause")
            return False

        self.logger.debug(f"SQL validation passed. Used aliases: {used_aliases}, Defined aliases: {defined_aliases}")
        return True

    def _validate_summary_sql(self, sql: str, intent_type: str, is_spatial: bool = False) -> tuple[bool, str]:
        """
        éªŒè¯ summary æŸ¥è¯¢çš„ SQL æ˜¯å¦æ­£ç¡®

        Summary æŸ¥è¯¢åº”è¯¥ï¼š
        1. ä½¿ç”¨èšåˆå‡½æ•°ï¼ˆCOUNTã€SUMã€AVGç­‰ï¼‰æˆ–ç©ºé—´èšåˆå‡½æ•°
        2. æ ¹æ®æ˜¯å¦ç©ºé—´æŸ¥è¯¢ä½¿ç”¨ä¸åŒçš„è§„åˆ™

        Args:
            sql: ç”Ÿæˆçš„ SQL
            intent_type: æŸ¥è¯¢æ„å›¾ç±»å‹ï¼ˆ"query" æˆ– "summary"ï¼‰
            is_spatial: æ˜¯å¦ç©ºé—´æŸ¥è¯¢

        Returns:
            (is_valid, warning_message): éªŒè¯ç»“æœå’Œè­¦å‘Šä¿¡æ¯
        """
        # åªéªŒè¯ summary ç±»å‹çš„æŸ¥è¯¢
        if intent_type != "summary":
            return (True, "")

        sql_lower = sql.lower()

        # ç©ºé—´ç»Ÿè®¡æŸ¥è¯¢çš„ç‰¹æ®Šè§„åˆ™
        if is_spatial:
            # ç©ºé—´ç»Ÿè®¡æŸ¥è¯¢å¿…é¡»åŒ…å«ç©ºé—´ç»´åº¦çš„ç»Ÿè®¡ï¼Œä¸èƒ½åªæœ‰ç®€å•è®¡æ•°

            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç©ºé—´å­—æ®µï¼ˆç»çº¬åº¦ï¼‰
            has_spatial_fields = any(keyword in sql_lower for keyword in ['lng_wgs84', 'lat_wgs84', 'lng', 'lat', 'longitude', 'latitude'])

            if not has_spatial_fields:
                return (False, "ç©ºé—´ç»Ÿè®¡æŸ¥è¯¢å¿…é¡»åŒ…å«ç©ºé—´å­—æ®µï¼ˆlng_wgs84ã€lat_wgs84 ç­‰ï¼‰")

            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç©ºé—´èšåˆæˆ–åˆ†ç»„
            spatial_aggregation_patterns = [
                r'avg\(.*?lng',           # AVG(lng_wgs84) - ä¸­å¿ƒç‚¹ç»åº¦
                r'avg\(.*?lat',           # AVG(lat_wgs84) - ä¸­å¿ƒç‚¹çº¬åº¦
                r'min\(.*?lng',           # MIN(lng_wgs84) - è¾¹ç•Œæ¡†
                r'max\(.*?lng',           # MAX(lng_wgs84) - è¾¹ç•Œæ¡†
                r'min\(.*?lat',           # MIN(lat_wgs84) - è¾¹ç•Œæ¡†
                r'max\(.*?lat',           # MAX(lat_wgs84) - è¾¹ç•Œæ¡†
                r'round\(.*?lng',         # ROUND(lng_wgs84) - å¯†åº¦åˆ†æ
                r'round\(.*?lat',         # ROUND(lat_wgs84) - å¯†åº¦åˆ†æ
                r'st_geohash',            # ST_GeoHash - åœ°ç†ç½‘æ ¼
                r'st_collect',            # ST_Collect - å‡ ä½•èšåˆ
                r'st_centroid',           # ST_Centroid - ä¸­å¿ƒç‚¹
                r'group by.*?è¡Œæ”¿åŒº',     # GROUP BY è¡Œæ”¿åŒº - æŒ‰åŒºåŸŸåˆ†ç»„
                r'group by.*?level',      # GROUP BY level - æŒ‰ç­‰çº§åˆ†ç»„
                r'group by.*?province',   # GROUP BY province - æŒ‰çœä»½åˆ†ç»„
                r'group by.*?city',       # GROUP BY city - æŒ‰åŸå¸‚åˆ†ç»„
            ]

            has_spatial_aggregation = any(
                re.search(pattern, sql_lower)
                for pattern in spatial_aggregation_patterns
            )

            if not has_spatial_aggregation:
                return (False, "ç©ºé—´ç»Ÿè®¡æŸ¥è¯¢å¿…é¡»åŒ…å«ç©ºé—´èšåˆï¼ˆAVG/MIN/MAXç»çº¬åº¦ã€GROUP BYåŒºåŸŸç­‰ï¼‰æˆ–ç©ºé—´åˆ†ç»„")

            # âš ï¸ ä¸¥æ ¼ç¦æ­¢ï¼šåªæœ‰ COUNT(*) è€Œæ²¡æœ‰ä»»ä½•ç©ºé—´ç»´åº¦
            # å…è®¸: COUNT(*) + AVG(lng/lat) æˆ– COUNT(*) + GROUP BY åŒºåŸŸ
            # ç¦æ­¢: åªæœ‰ COUNT(*) è€Œæ²¡æœ‰å…¶ä»–ç©ºé—´å­—æ®µ
            if 'count(*)' in sql_lower:
                # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å«ç©ºé—´èšåˆå­—æ®µï¼ˆAVG/MIN/MAXç»çº¬åº¦ï¼‰
                has_spatial_agg_fields = any(
                    re.search(pattern, sql_lower)
                    for pattern in [
                        r'avg\(.*?lng', r'avg\(.*?lat',
                        r'min\(.*?lng', r'max\(.*?lng',
                        r'min\(.*?lat', r'max\(.*?lat'
                    ]
                )

                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº† GROUP BY
                has_group_by = 'group by' in sql_lower

                if not has_spatial_agg_fields and not has_group_by:
                    return (False, "ç©ºé—´ç»Ÿè®¡æŸ¥è¯¢ä¸èƒ½åªè¿”å› COUNT(*)ï¼Œå¿…é¡»åŒ…å«ç©ºé—´ç»´åº¦ï¼ˆAVGç»çº¬åº¦ã€è¾¹ç•Œæ¡†ã€GROUP BYåŒºåŸŸç­‰ï¼‰")

            # é€šè¿‡éªŒè¯
            self.logger.debug(f"Spatial summary SQL validation passed for: {sql[:50]}...")
            return (True, "")

        # æ™®é€šç»Ÿè®¡æŸ¥è¯¢çš„è§„åˆ™
        else:
            # æ£€æŸ¥1: æ™®é€šç»Ÿè®¡æŸ¥è¯¢ä¸åº”è¯¥ä½¿ç”¨ json_agg
            if 'json_agg' in sql_lower:
                return (False, "æ™®é€šç»Ÿè®¡æŸ¥è¯¢ä¸åº”è¯¥ä½¿ç”¨ json_aggï¼Œåº”è¯¥ç›´æ¥ä½¿ç”¨ COUNT/SUM/AVG ç­‰èšåˆå‡½æ•°")

            # æ£€æŸ¥2: æ™®é€šç»Ÿè®¡æŸ¥è¯¢åº”è¯¥åŒ…å«èšåˆå‡½æ•°
            aggregation_keywords = ['count(', 'sum(', 'avg(', 'max(', 'min(', 'group by']
            has_aggregation = any(keyword in sql_lower for keyword in aggregation_keywords)

            if not has_aggregation:
                return (False, "æ™®é€šç»Ÿè®¡æŸ¥è¯¢åº”è¯¥åŒ…å«èšåˆå‡½æ•°ï¼ˆCOUNTã€SUMã€AVG ç­‰ï¼‰æˆ– GROUP BY å­å¥")

            # é€šè¿‡éªŒè¯
            self.logger.debug(f"Non-spatial summary SQL validation passed for: {sql[:50]}...")
            return (True, "")

    def _fix_summary_sql_if_needed(self, sql: str, intent_type: str) -> str:
        """
        å¦‚æœ Summary SQL åŒ…å« json_aggï¼Œè‡ªåŠ¨è½¬æ¢ä¸º COUNT

        Args:
            sql: åŸå§‹ SQL
            intent_type: æŸ¥è¯¢æ„å›¾ç±»å‹

        Returns:
            ä¿®å¤åçš„ SQL
        """
        if intent_type != "summary":
            return sql

        sql_lower = sql.lower()

        # æ£€æŸ¥æ˜¯å¦åŒ…å« json_aggï¼ˆé”™è¯¯çš„ Summary SQLï¼‰
        if 'json_agg' not in sql_lower:
            return sql

        self.logger.warning("Detected json_agg in Summary SQL, auto-fixing to COUNT")

        try:
            # æå– FROM å­å¥
            from_match = re.search(
                r'FROM\s+(.+?)(?:WHERE|GROUP|ORDER|LIMIT|$)',
                sql,
                re.IGNORECASE | re.DOTALL
            )

            # æå– WHERE å­å¥
            where_match = re.search(
                r'WHERE\s+(.+?)(?:GROUP|ORDER|LIMIT|$)',
                sql,
                re.IGNORECASE | re.DOTALL
            )

            # æå– GROUP BY å­å¥
            group_match = re.search(
                r'GROUP\s+BY\s+(.+?)(?:ORDER|LIMIT|$)',
                sql,
                re.IGNORECASE | re.DOTALL
            )

            # æå– ORDER BY å­å¥
            order_match = re.search(
                r'ORDER\s+BY\s+(.+?)(?:LIMIT|$)',
                sql,
                re.IGNORECASE | re.DOTALL
            )

            # æå– LIMIT å­å¥
            limit_match = re.search(
                r'LIMIT\s+(\d+)',
                sql,
                re.IGNORECASE
            )

            # é‡å»ºä¸ºç®€å• COUNT SQL
            fixed_sql = "SELECT COUNT(*) as count\n"

            if from_match:
                from_clause = from_match.group(1).strip()
                # ç§»é™¤å¯èƒ½çš„å­æŸ¥è¯¢åˆ«å
                from_clause = re.sub(r'\)\s+\w+\s*$', ')', from_clause)
                fixed_sql += f"FROM {from_clause}\n"

            if where_match:
                where_clause = where_match.group(1).strip()
                fixed_sql += f"WHERE {where_clause}\n"

            if group_match:
                group_clause = group_match.group(1).strip()
                fixed_sql += f"GROUP BY {group_clause}\n"

            if order_match:
                order_clause = order_match.group(1).strip()
                fixed_sql += f"ORDER BY {order_clause}\n"

            if limit_match:
                limit_value = limit_match.group(1)
                fixed_sql += f"LIMIT {limit_value}\n"

            self.logger.info(f"Auto-fixed Summary SQL: removed json_agg, using COUNT")
            self.logger.debug(f"Fixed SQL: {fixed_sql[:100]}...")

            return fixed_sql

        except Exception as e:
            self.logger.error(f"Failed to auto-fix Summary SQL: {e}")
            # ä¿®å¤å¤±è´¥ï¼Œè¿”å›åŸ SQL
            return sql

    def _build_default_from_clause(self, uses_a: bool, uses_t: bool) -> str:
        """
        æ„å»ºç¼ºå¤± FROM å­å¥æ—¶çš„é»˜è®¤è¡¨å…³è”ã€‚
        """
        if uses_a and uses_t:
            lines = [
                "FROM a_sight a",
                "LEFT JOIN tourist_spot t ON t.name LIKE a.name || '%'",
                "    OR TRIM(SPLIT_PART(t.name, ' ', 1)) = a.name",
            ]
            return "\n".join(lines) + "\n"

        if uses_a:
            return "FROM a_sight a\n"

        if uses_t:
            return "FROM tourist_spot t\n"

        return "FROM a_sight a\n"

    def _add_from_clause_if_missing(self, sql: str, query: str) -> str:
        """
        å½“SQLç¼ºå°‘FROMå­å¥æˆ–åˆ«åå®šä¹‰æ—¶ï¼Œè‡ªåŠ¨è¡¥å…¨ã€‚

        å¢å¼ºåŠŸèƒ½ï¼š
        - æ”¯æŒä»»æ„è¡¨åˆ«åçš„æ£€æµ‹å’Œä¿®å¤
        - å¤„ç†å¤šè¡¨è¿æ¥å’Œå­æŸ¥è¯¢åœºæ™¯
        - æ›´æ™ºèƒ½çš„FROMå­å¥é‡å»º

        Args:
            sql: åŸå§‹SQL
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            ä¿®æ­£åçš„SQL
        """
        fixed_sql = sql
        newline = '\n'
        
        # æå–æ‰€æœ‰ä½¿ç”¨çš„è¡¨åˆ«å
        alias_pattern = r'\b([a-z_][a-z0-9_]*)\.\w+'
        used_aliases = set(re.findall(alias_pattern, sql.lower()))
        
        # ç§»é™¤ç³»ç»Ÿå…³é”®å­—
        system_keywords = {'select', 'from', 'where', 'group', 'order', 'having', 'limit', 'offset', 'join', 'on', 'as', 'and', 'or', 'not', 'in', 'is', 'null', 'true', 'false'}
        used_aliases = used_aliases - system_keywords
        
        # ç‰¹æ®Šå¤„ç†ï¼šæ£€æµ‹å¸¸ç”¨çš„è¡¨åˆ«åæ¨¡å¼
        uses_a = 'a' in used_aliases
        uses_t = 't' in used_aliases
        
        # å°è¯•è‡ªåŠ¨ä¿®å¤è¡¨åˆ«åå®šä¹‰
        alias_adjusted = False
        
        # ä¿®å¤ a_sight è¡¨çš„åˆ«åå®šä¹‰
        if uses_a:
            fixed_sql, count_a = re.subn(
                r'\ba_sight\b(?!\s+(?:as\s+)?a\b)',
                'a_sight a',
                fixed_sql,
                count=1,
                flags=re.IGNORECASE
            )
            if count_a:
                alias_adjusted = True

        # ä¿®å¤ tourist_spot è¡¨çš„åˆ«åå®šä¹‰
        if uses_t:
            fixed_sql, count_t = re.subn(
                r'\btourist_spot\b(?!\s+(?:as\s+)?t\b)',
                'tourist_spot t',
                fixed_sql,
                count=1,
                flags=re.IGNORECASE
            )
            if count_t:
                alias_adjusted = True

        sql_lower = fixed_sql.lower()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ FROMå­å¥
        needs_default_from = 'from' not in sql_lower
        
        # æ£€æŸ¥åˆ«åæ˜¯å¦å·²å®šä¹‰
        for alias in used_aliases:
            # æ£€æŸ¥FROMå­å¥ä¸­æ˜¯å¦å®šä¹‰äº†è¯¥åˆ«å
            if not re.search(rf'\bfrom\s+.*\b(?:as\s+)?{alias}\b', sql_lower):
                needs_default_from = True
                break

        # å¦‚æœéœ€è¦æ·»åŠ FROMå­å¥ï¼Œæ„å»ºåˆé€‚çš„FROMå­å¥
        if needs_default_from:
            # æ ¹æ®ä½¿ç”¨çš„åˆ«åæ„å»ºFROMå­å¥
            default_from = self._build_enhanced_from_clause(used_aliases)

            from_match = re.search(r'\bfrom\b', fixed_sql, re.IGNORECASE)
            if from_match:
                # å·²æœ‰FROMå­å¥ä½†åˆ«åå®šä¹‰ä¸å®Œæ•´ï¼Œéœ€è¦é‡å»º
                after_from = fixed_sql[from_match.end():]
                boundary_match = re.search(
                    r'\bWHERE\b|\bGROUP\s+BY\b|\bORDER\s+BY\b|\bLIMIT\b|\bHAVING\b|\bUNION\b|\bEXCEPT\b|\bINTERSECT\b',
                    after_from,
                    re.IGNORECASE
                )
                if boundary_match:
                    end_index = from_match.end() + boundary_match.start()
                else:
                    end_index = len(fixed_sql)

                original_from_segment = fixed_sql[from_match.start():end_index]
                trailing_clause = fixed_sql[end_index:]

                # ä¿ç•™åŸæœ‰çš„JOINå­å¥
                join_pattern = re.compile(
                    r'\b(?:INNER|LEFT|RIGHT|FULL|CROSS)\s+JOIN\b|\bJOIN\b',
                    re.IGNORECASE
                )
                join_match = join_pattern.search(original_from_segment)
                trailing_joins = ''
                if join_match:
                    trailing_joins = original_from_segment[join_match.start():].strip()

                # é‡å»ºFROMå­å¥
                rebuilt_from = default_from.rstrip(newline)
                if trailing_joins:
                    rebuilt_from = f"{rebuilt_from}{newline}{trailing_joins.strip()}"
                rebuilt_from = f"{rebuilt_from}{newline}"

                prefix = fixed_sql[:from_match.start()].rstrip()
                if prefix and not prefix.endswith(newline):
                    prefix += newline
                suffix = trailing_clause.lstrip()
                fixed_sql = f"{prefix}{rebuilt_from}{suffix}"
            else:
                # å®Œå…¨æ²¡æœ‰FROMå­å¥ï¼Œéœ€è¦æ’å…¥
                before_where = re.search(r'\bWHERE\b', fixed_sql, re.IGNORECASE)
                if before_where:
                    prefix = fixed_sql[:before_where.start()].rstrip()
                    if prefix and not prefix.endswith(newline):
                        prefix += newline
                    suffix = fixed_sql[before_where.start():]
                    fixed_sql = f"{prefix}{default_from}{suffix}"
                else:
                    trimmed = fixed_sql.rstrip()
                    if trimmed and not trimmed.endswith(newline):
                        trimmed += newline
                    fixed_sql = f"{trimmed}{default_from}"

            self.logger.info(f"Auto-rebuilt FROM clause for aliases: {used_aliases}")
        else:
            if alias_adjusted:
                self.logger.info("Auto-added missing table aliases in FROM clause")
            else:
                self.logger.info("SQL structure appears valid, no changes needed")

        # æœ€ç»ˆéªŒè¯ä¿®å¤åçš„SQL
        if not self._validate_sql_structure(fixed_sql):
            self.logger.warning("Auto-repair failed, SQL structure still invalid")
            # å¦‚æœè‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯ç”¨äºè°ƒè¯•
            self.logger.debug(f"Failed to repair SQL: {fixed_sql}")

        return fixed_sql

    def _build_enhanced_from_clause(self, used_aliases: set) -> str:
        """
        æ ¹æ®ä½¿ç”¨çš„åˆ«åæ„å»ºå¢å¼ºçš„FROMå­å¥

        Args:
            used_aliases: ä½¿ç”¨çš„è¡¨åˆ«åé›†åˆ

        Returns:
            æ„å»ºçš„FROMå­å¥å­—ç¬¦ä¸²
        """
        lines = []
        
        # å¤„ç†å¸¸è§çš„è¡¨åˆ«åç»„åˆ
        if 'a' in used_aliases and 't' in used_aliases:
            lines = [
                "FROM a_sight a",
                "LEFT JOIN tourist_spot t ON t.name LIKE a.name || '%'",
                "    OR TRIM(SPLIT_PART(t.name, ' ', 1)) = a.name"
            ]
        elif 'a' in used_aliases:
            lines = ["FROM a_sight a"]
        elif 't' in used_aliases:
            lines = ["FROM tourist_spot t"]
        else:
            # é»˜è®¤ä½¿ç”¨a_sightè¡¨
            lines = ["FROM a_sight a"]
            
            # å¦‚æœä½¿ç”¨äº†å…¶ä»–æœªçŸ¥åˆ«åï¼Œå°è¯•æ·»åŠ å®ƒä»¬
            for alias in used_aliases:
                if alias not in ['a', 't']:
                    self.logger.warning(f"Unknown table alias '{alias}' used, cannot auto-resolve")
        
        return "\n".join(lines) + "\n"

    def fix_sql_with_context(
        self,
        sql: str,
        error_context: Dict[str, Any],
        query: str,
        database_schema: Optional[str] = None
    ) -> str:
        """
        ä½¿ç”¨é”™è¯¯ä¸Šä¸‹æ–‡å¢å¼ºä¿®å¤SQL

        Args:
            sql: åŸå§‹SQL
            error_context: é”™è¯¯ä¸Šä¸‹æ–‡ä¿¡æ¯
                - failed_sql: å¤±è´¥çš„SQL
                - error_message: é”™è¯¯ä¿¡æ¯
                - error_code: PostgreSQLé”™è¯¯ç 
                - error_position: é”™è¯¯ä½ç½®
                - failed_at_step: å¤±è´¥æ­¥éª¤
                - query_context: æŸ¥è¯¢ä¸Šä¸‹æ–‡
                - database_context: æ•°æ®åº“ä¸Šä¸‹æ–‡
                - execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            query: åŸå§‹æŸ¥è¯¢
            database_schema: æ ¼å¼åŒ–çš„æ•°æ®åº“Schemaå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¿®å¤åçš„SQL
        """
        try:
            # âœ… å¦‚æœæ²¡æœ‰æä¾›schemaï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            schema_str = self._resolve_schema_for_prompt(database_schema)

            # âœ… æå–é”™è¯¯ä¸Šä¸‹æ–‡ä¿¡æ¯
            error_message = error_context.get("error_message", "")
            error_code = error_context.get("error_code", "")
            error_position = error_context.get("error_position")
            failed_at_step = error_context.get("failed_at_step", 0)
            
            # âœ… æå–æŸ¥è¯¢ä¸Šä¸‹æ–‡
            query_context = error_context.get("query_context", {})
            original_query = query_context.get("original_query", query)
            enhanced_query = query_context.get("enhanced_query", query)
            intent_type = query_context.get("intent_type", "query")
            requires_spatial = query_context.get("requires_spatial", False)
            
            # âœ… æå–æ•°æ®åº“ä¸Šä¸‹æ–‡
            database_context = error_context.get("database_context", {})
            schema_used = database_context.get("schema_used", {})
            tables_accessed = database_context.get("tables_accessed", [])
            
            # âœ… æå–æ‰§è¡Œä¸Šä¸‹æ–‡
            execution_context = error_context.get("execution_context", {})
            execution_time_ms = execution_context.get("execution_time_ms", 0)
            rows_affected = execution_context.get("rows_affected", 0)

            # âœ… å¢å¼ºä¿®å¤æç¤ºè¯ï¼ˆåˆ©ç”¨å®Œæ•´çš„é”™è¯¯ä¸Šä¸‹æ–‡ï¼‰
            fix_prompt = f"""ä½ æ˜¯ä¸€ä¸ªç²¾é€š PostgreSQL å’Œ PostGIS çš„ SQL ä¸“å®¶ã€‚

**æ•°æ®åº“Schemaä¿¡æ¯**ï¼ˆå®Œæ•´å­—æ®µç±»å‹ä¾›ä½ å‚è€ƒï¼‰:
{schema_str}

**ç”¨æˆ·éœ€æ±‚**: {original_query}
**å¢å¼ºæŸ¥è¯¢**: {enhanced_query}
**æŸ¥è¯¢æ„å›¾**: {intent_type} (query=å…·ä½“æ•°æ® / summary=ç»Ÿè®¡ç»“æœ)
**ç©ºé—´æŸ¥è¯¢**: {requires_spatial}

**å¤±è´¥çš„ SQL**:
```sql
{sql}
```

**æ‰§è¡Œé”™è¯¯è¯¦æƒ…**:
- é”™è¯¯ä¿¡æ¯: {error_message}
- PostgreSQL é”™è¯¯ç : {error_code}
- é”™è¯¯ä½ç½®: {error_position}
- å¤±è´¥æ­¥éª¤: {failed_at_step}
- æ‰§è¡Œè€—æ—¶: {execution_time_ms:.0f}ms
- å½±å“è¡Œæ•°: {rows_affected}

**æ•°æ®åº“ä¸Šä¸‹æ–‡**:
- ä½¿ç”¨çš„è¡¨: {', '.join(tables_accessed) if tables_accessed else 'æœªçŸ¥'}
- Schema çŠ¶æ€: {'å·²åŠ è½½' if schema_used else 'æœªåŠ è½½'}

---

## ğŸ¤” è¯·è¿ç”¨ä½ çš„ PostgreSQL ä¸“ä¸šçŸ¥è¯†è¿›è¡Œæ·±åº¦è¯Šæ–­å’Œä¿®å¤

### æ€è€ƒæ¡†æ¶ï¼š

1. **é”™è¯¯æ·±åº¦åˆ†æ**
   - æ ¹æ® PostgreSQL é”™è¯¯ç  {error_code}ï¼Œè¿™æ˜¯ä»€ä¹ˆç±»å‹çš„é”™è¯¯ï¼Ÿ
   - é”™è¯¯ä½ç½® {error_position} æŒ‡å‘ SQL çš„å“ªä¸ªéƒ¨åˆ†ï¼Ÿ
   - ç»“åˆæŸ¥è¯¢æ„å›¾ {intent_type} å’Œç©ºé—´éœ€æ±‚ {requires_spatial}ï¼Œåˆ†ææ ¹æœ¬åŸå› 

2. **ä¸Šä¸‹æ–‡å…³è”åˆ†æ**
   - ç”¨æˆ·çœŸæ­£éœ€è¦ä»€ä¹ˆæ•°æ®ï¼Ÿï¼ˆå‚è€ƒåŸå§‹éœ€æ±‚: {original_query}ï¼‰
   - å½“å‰ SQL ç»“æ„æ˜¯å¦åŒ¹é…æŸ¥è¯¢æ„å›¾ï¼Ÿ
   - ä½¿ç”¨çš„è¡¨ {tables_accessed} æ˜¯å¦åˆé€‚ï¼Ÿ
   - æ‰§è¡Œè€—æ—¶ {execution_time_ms:.0f}ms æ˜¯å¦æš—ç¤ºæ€§èƒ½é—®é¢˜ï¼Ÿ

3. **ä¿®å¤ç­–ç•¥åˆ¶å®š**
   - å¦‚ä½•ä¿æŒæŸ¥è¯¢æ„å›¾ {intent_type} çš„åŒæ—¶ä¿®å¤é”™è¯¯ï¼Ÿ
   - æ˜¯å¦éœ€è¦è°ƒæ•´ï¼šè¡¨è¿æ¥ç­–ç•¥ã€èšåˆå‡½æ•°ä½¿ç”¨ã€å­æŸ¥è¯¢ç»“æ„ã€å­—æ®µä½œç”¨åŸŸï¼Ÿ
   - å¯¹äºç©ºé—´æŸ¥è¯¢ {requires_spatial}ï¼ŒPostGIS å‡½æ•°ä½¿ç”¨æ˜¯å¦æ­£ç¡®ï¼Ÿ
   - å¦‚ä½•ä¼˜åŒ–æ€§èƒ½é¿å…è¶…æ—¶ï¼Ÿ

4. **æœ€ä½³å®è·µéªŒè¯**
   - ä¿®å¤åçš„ SQL æ˜¯å¦ç¬¦åˆ PostgreSQL è¯­æ³•è§„èŒƒï¼Ÿ
   - æ˜¯å¦è€ƒè™‘äº†æ•°æ®ç±»å‹åŒ¹é…ï¼Ÿï¼ˆå‚è€ƒä¸Šæ–¹Schemaä¿¡æ¯ï¼‰
   - æ˜¯å¦å¤„ç†äº†å¯èƒ½çš„ NULL å€¼å’Œè¾¹ç•Œæƒ…å†µï¼Ÿ
   - æ˜¯å¦åˆ©ç”¨äº†é€‚å½“çš„ç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ–ï¼Ÿ

---

## ğŸ“š ç›¸å…³èƒŒæ™¯çŸ¥è¯†ï¼ˆä¾›å‚è€ƒï¼‰

**PostgreSQL æ ¸å¿ƒè§„åˆ™**:
- èšåˆæŸ¥è¯¢æ—¶ï¼ŒSELECT/WHERE/HAVING ä¸­å¼•ç”¨çš„éèšåˆå­—æ®µå¿…é¡»åœ¨ GROUP BY ä¸­
- å­æŸ¥è¯¢çš„è¡¨åˆ«åä½œç”¨åŸŸä»…é™äºè¯¥å­æŸ¥è¯¢å†…éƒ¨ï¼Œå¤–å±‚æ— æ³•ç›´æ¥è®¿é—®
- UNION ALL è¦æ±‚å„å­æŸ¥è¯¢è¿”å›ç›¸åŒæ•°é‡ã€é¡ºåºå’Œç±»å‹çš„å­—æ®µ
- FROM å­å¥å¿…é¡»å…ˆå®šä¹‰è¡¨å’Œåˆ«åï¼Œæ‰èƒ½åœ¨ SELECT/WHERE ä¸­ä½¿ç”¨
- å¯¹äºç©ºé—´æŸ¥è¯¢ï¼Œç¡®ä¿ PostGIS å‡½æ•°å‚æ•°ç±»å‹æ­£ç¡®

**å¸¸è§é”™è¯¯ç è§£è¯»**:
- 42P01: è¡¨ä¸å­˜åœ¨
- 42703: åˆ—ä¸å­˜åœ¨
- 42601: è¯­æ³•é”™è¯¯
- 42883: å‡½æ•°ä¸å­˜åœ¨ï¼ˆå¸¸è§äº PostGIS å‡½æ•°ï¼‰

---

è¯·åŸºäºå®Œæ•´çš„é”™è¯¯ä¸Šä¸‹æ–‡å’Œä½ çš„ SQL ä¸“ä¸šçŸ¥è¯†ï¼Œç”Ÿæˆä¿®å¤åçš„ SQL è¯­å¥ã€‚

åªè¿”å›ä¿®å¤åçš„ SQLï¼Œä¸è¦è§£é‡Šã€‚

ä¿®å¤åçš„ SQL:"""

            # è°ƒç”¨LLMç”Ÿæˆä¿®å¤åçš„SQL
            self.logger.debug(f"Attempting to fix SQL with enhanced context, error_code: {error_code}")
            response = self.llm.llm.invoke(fix_prompt)

            # æå–ä¿®å¤åçš„SQL
            fixed_sql = self._extract_sql(response)

            # âœ… éªŒè¯ä¿®å¤åçš„SQLæ˜¯å¦åŒ…å«FROMå­å¥
            if not self._validate_sql_structure(fixed_sql):
                self.logger.warning("Fixed SQL still missing FROM clause, adding it manually")
                fixed_sql = self._add_from_clause_if_missing(fixed_sql, query)

            self.logger.info(f"SQL fixed with enhanced context: {fixed_sql[:100]}...")
            return fixed_sql

        except Exception as e:
            self.logger.error(f"Failed to fix SQL with context: {e}")
            # å¦‚æœä¿®å¤å¤±è´¥ï¼Œå›é€€åˆ°åŸºæœ¬ä¿®å¤æ–¹æ³•
            return self.fix_sql_with_error(sql, error_context.get("error_message", ""), query, database_schema)

    def simplify_sql(self, sql: str, max_limit: int = 100) -> str:
        """
        ç®€åŒ–SQLæŸ¥è¯¢ä»¥é¿å…è¶…æ—¶

        ç­–ç•¥:
        1. æ·»åŠ LIMITé™åˆ¶
        2. ç§»é™¤å¤æ‚çš„å­æŸ¥è¯¢ï¼ˆå¦‚æœæœ‰ï¼‰
        3. ä¿ç•™æ ¸å¿ƒå­—æ®µ

        Args:
            sql: åŸå§‹SQL
            max_limit: æœ€å¤§è®°å½•æ•°ï¼ˆé»˜è®¤100ï¼‰

        Returns:
            ç®€åŒ–åçš„SQL
        """
        try:
            import re
            self.logger.info(f"Simplifying SQL, adding LIMIT {max_limit}")

            # å…ˆç§»é™¤æœ«å°¾çš„åˆ†å·
            sql = sql.rstrip().rstrip(';')

            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰LIMITï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            if re.search(r'\bLIMIT\s+\d+', sql, flags=re.IGNORECASE):
                # æ›¿æ¢ç°æœ‰çš„LIMIT
                sql = re.sub(r'\bLIMIT\s+\d+', f'LIMIT {max_limit}', sql, flags=re.IGNORECASE)
                self.logger.debug("Replaced existing LIMIT")
            else:
                # æ·»åŠ LIMIT
                sql = f"{sql}\nLIMIT {max_limit}"
                self.logger.debug("Added LIMIT clause")

            return sql

        except Exception as e:
            self.logger.error(f"Failed to simplify SQL: {e}")
            # ç®€åŒ–å¤±è´¥ï¼Œç›´æ¥åœ¨æœ«å°¾æ·»åŠ LIMIT
            return f"{sql.rstrip().rstrip(';')}\nLIMIT {max_limit}"


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    print("=== SQLGenerator æµ‹è¯• ===\n")

    # æµ‹è¯•åˆ†æç¼ºå¤±ä¿¡æ¯
    print("--- æµ‹è¯•1: åˆ†æç¼ºå¤±ä¿¡æ¯ ---")
    generator = SQLGenerator(None, "æµ‹è¯•æç¤ºè¯")

    test_data = [
        {
            "name": "è¥¿æ¹–",
            "level": "5A",
            "coordinates": [120.15, 30.28]
            # ç¼ºå°‘: address, è¯„åˆ†, é—¨ç¥¨, ä»‹ç», å›¾ç‰‡é“¾æ¥
        }
    ]

    analysis = generator.analyze_missing_info("æŸ¥è¯¢è¥¿æ¹–", test_data)
    print(f"Has missing: {analysis['has_missing']}")
    print(f"Missing fields: {analysis['missing_fields']}")
    print(f"Data complete: {analysis['data_complete']}")
    print(f"Suggestion: {analysis['suggestion']}")
