#!/usr/bin/env python3
"""
ç‹¬ç«‹æµ‹è¯•æŸ¥è¯¢æ„å›¾åˆ†æç³»ç»Ÿ
é¿å…ä¾èµ–é—®é¢˜ï¼Œç›´æ¥æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½
"""

import re
from typing import Dict, Any, List

# å¤åˆ¶æ ¸å¿ƒåˆ†æé€»è¾‘åˆ°ç‹¬ç«‹è„šæœ¬ä¸­
class SimpleIntentAnalyzer:
    """ç®€åŒ–çš„æ„å›¾åˆ†æå™¨"""
    
    def __init__(self):
        # ç©ºé—´æŸ¥è¯¢å…³é”®è¯
        self.spatial_keywords = [
            'è·ç¦»', 'é™„è¿‘', 'å‘¨å›´', 'èŒƒå›´å†…', 'æœ€è¿‘', 'è·¯å¾„', 'è·¯çº¿',
            'ç›¸äº¤', 'åŒ…å«', 'åœ¨å†…', 'è¾¹ç•Œ', 'ç¼“å†²', 'ç¼“å†²åŒº',
            'distance', 'near', 'nearby', 'around', 'within',
            'route', 'path', 'nearest', 'proximity', 'intersect',
            'contain', 'buffer', 'st_', 'dwithin'
        ]
        
        # æ€»ç»“/ç»Ÿè®¡ç±»æŸ¥è¯¢å…³é”®è¯
        self.summary_keywords = [
            'ç»Ÿè®¡', 'æ€»ç»“', 'æ±‡æ€»', 'å¤šå°‘', 'æ•°é‡', 'åˆ†å¸ƒ',
            'å¹³å‡', 'æœ€å¤š', 'æœ€å°‘', 'æ’å', 'æ€»æ•°', 'è®¡æ•°',
            'æœ‰å‡ ä¸ª', 'æœ‰å¤šå°‘', 'å‡ ä¸ª', 'åˆ†æ',
            'count', 'sum', 'average', 'max', 'min', 'total',
            'statistics', 'summary', 'analyze', 'how many'
        ]

    def analyze_query_intent(self, query: str) -> Dict[str, Any]:
        """
        æ™ºèƒ½åˆ†ææŸ¥è¯¢æ„å›¾ï¼ˆåŸºäºå¤šç»´åº¦ç‰¹å¾åˆ†æï¼‰
        """
        query_lower = query.lower()
        
        # åˆå§‹åŒ–åˆ†æç»“æœ
        analysis_details = {
            "summary_score": 0.0,
            "spatial_score": 0.0,
            "scenic_score": 0.0,
            "matched_patterns": []
        }

        # ==================== ç»Ÿè®¡æ„å›¾åˆ†æ ====================
        summary_score = 0.0
        
        # å¼ºç»Ÿè®¡å…³é”®è¯ï¼ˆæƒé‡é«˜ï¼‰
        strong_summary_keywords = ['ç»Ÿè®¡', 'è®¡æ•°', 'æ•°é‡', 'å¤šå°‘ä¸ª', 'count', 'how many', 'æ€»æ•°', 'æ€»è®¡']
        for keyword in strong_summary_keywords:
            if keyword in query_lower:
                summary_score += 0.3
                analysis_details["matched_patterns"].append(f"å¼ºç»Ÿè®¡å…³é”®è¯: {keyword}")
        
        # å¼±ç»Ÿè®¡å…³é”®è¯ï¼ˆæƒé‡ä¸­ï¼‰
        weak_summary_keywords = ['æ±‡æ€»', 'æ€»ç»“', 'åˆ†å¸ƒ', 'å¹³å‡', 'æœ€å¤š', 'æœ€å°‘', 'sum', 'average', 'max', 'min']
        for keyword in weak_summary_keywords:
            if keyword in query_lower:
                summary_score += 0.15
                analysis_details["matched_patterns"].append(f"å¼±ç»Ÿè®¡å…³é”®è¯: {keyword}")
        
        # ç»Ÿè®¡æ¨¡å¼è¯†åˆ«
        summary_patterns = [
            (r'æœ‰å¤šå°‘ä¸ª?', 0.4),
            (r'å‡ ä¸ª', 0.3),
            (r'(\d+)ä¸ª', 0.2),
            (r'æ’å', 0.25),
            (r'åˆ†å¸ƒæƒ…å†µ', 0.3)
        ]
        
        for pattern, weight in summary_patterns:
            if re.search(pattern, query_lower):
                summary_score += weight
                analysis_details["matched_patterns"].append(f"ç»Ÿè®¡æ¨¡å¼: {pattern}")
        
        analysis_details["summary_score"] = min(summary_score, 1.0)

        # ==================== ç©ºé—´æ„å›¾åˆ†æ ====================
        spatial_score = 0.0
        
        # å¼ºç©ºé—´å…³é”®è¯ï¼ˆæƒé‡é«˜ï¼‰
        strong_spatial_keywords = ['è·ç¦»', 'é™„è¿‘', 'å‘¨å›´', 'èŒƒå›´å†…', 'æœ€è¿‘', 'dwithin', 'st_', 'buffer']
        for keyword in strong_spatial_keywords:
            if keyword in query_lower:
                spatial_score += 0.25
                analysis_details["matched_patterns"].append(f"å¼ºç©ºé—´å…³é”®è¯: {keyword}")
        
        # å¼±ç©ºé—´å…³é”®è¯ï¼ˆæƒé‡ä¸­ï¼‰
        weak_spatial_keywords = ['è·¯å¾„', 'è·¯çº¿', 'ç›¸äº¤', 'åŒ…å«', 'è¾¹ç•Œ', 'ç¼“å†²', 'near', 'around', 'within']
        for keyword in weak_spatial_keywords:
            if keyword in query_lower:
                spatial_score += 0.1
                analysis_details["matched_patterns"].append(f"å¼±ç©ºé—´å…³é”®è¯: {keyword}")
        
        # ç©ºé—´æ¨¡å¼è¯†åˆ«
        spatial_patterns = [
            (r'è·ç¦».*[å…¬é‡Œ|åƒç±³|ç±³]', 0.4),
            (r'é™„è¿‘.*[å…¬é‡Œ|åƒç±³|ç±³]', 0.35),
            (r'å‘¨å›´.*[å…¬é‡Œ|åƒç±³|ç±³]', 0.35),
            (r'èŒƒå›´å†….*[å…¬é‡Œ|åƒç±³|ç±³]', 0.3),
            (r'ç»çº¬åº¦', 0.25),
            (r'åæ ‡', 0.2)
        ]
        
        for pattern, weight in spatial_patterns:
            if re.search(pattern, query_lower):
                spatial_score += weight
                analysis_details["matched_patterns"].append(f"ç©ºé—´æ¨¡å¼: {pattern}")
        
        analysis_details["spatial_score"] = min(spatial_score, 1.0)

        # ==================== æ™¯åŒºæ„å›¾åˆ†æ ====================
        scenic_score = 0.0
        
        # æ™¯åŒºç›¸å…³å…³é”®è¯
        scenic_keywords = ['æ™¯åŒº', 'æ™¯ç‚¹', 'æ—…æ¸¸', '5a', '4a', '3a', '2a', '1a', 'scenic', 'tourist', 'spot']
        for keyword in scenic_keywords:
            if keyword in query_lower:
                scenic_score += 0.1
                analysis_details["matched_patterns"].append(f"æ™¯åŒºå…³é”®è¯: {keyword}")
        
        # æ™¯åŒºç­‰çº§æ¨¡å¼
        level_patterns = [
            (r'[54321]aæ™¯åŒº', 0.3),
            (r'[54321]açº§', 0.3),
            (r'[54321]aæ™¯ç‚¹', 0.3)
        ]
        
        for pattern, weight in level_patterns:
            if re.search(pattern, query_lower):
                scenic_score += weight
                analysis_details["matched_patterns"].append(f"æ™¯åŒºç­‰çº§æ¨¡å¼: {pattern}")
        
        analysis_details["scenic_score"] = min(scenic_score, 1.0)

        # ==================== æ„å›¾å†³ç­– ====================
        
        # ç¡®å®šæ„å›¾ç±»å‹ï¼ˆåŸºäºåˆ†æ•°é˜ˆå€¼ï¼‰
        is_summary = analysis_details["summary_score"] >= 0.4
        is_spatial = analysis_details["spatial_score"] >= 0.3
        
        # ç¡®å®šæ„å›¾ç±»å‹
        intent_type = "summary" if is_summary else "query"
        
        # è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦
        confidence = max(
            analysis_details["summary_score"],
            analysis_details["spatial_score"],
            analysis_details["scenic_score"]
        )
        
        # æ„å»ºæè¿°
        description_parts = []
        if is_summary:
            description_parts.append(f"ç»Ÿè®¡æ±‡æ€»æŸ¥è¯¢(ç½®ä¿¡åº¦:{analysis_details['summary_score']:.2f})")
        else:
            description_parts.append(f"æ•°æ®æŸ¥è¯¢")
        
        if is_spatial:
            description_parts.append(f"ç©ºé—´æŸ¥è¯¢(ç½®ä¿¡åº¦:{analysis_details['spatial_score']:.2f})")
        
        if scenic_score > 0.2:
            description_parts.append(f"æ™¯åŒºæŸ¥è¯¢(ç½®ä¿¡åº¦:{analysis_details['scenic_score']:.2f})")
        
        description = " - ".join(description_parts)

        # æ”¶é›†åŒ¹é…çš„å…³é”®è¯
        spatial_matched = [kw for kw in self.spatial_keywords if kw in query_lower]
        summary_matched = [kw for kw in self.summary_keywords if kw in query_lower]

        return {
            "intent_type": intent_type,
            "is_spatial": is_spatial,
            "keywords_matched": spatial_matched + summary_matched,
            "description": description,
            "confidence": confidence,
            "analysis_details": analysis_details
        }

def test_intent_analysis():
    """æµ‹è¯•æ„å›¾åˆ†æç³»ç»Ÿ"""
    print("=== æŸ¥è¯¢æ„å›¾åˆ†æç³»ç»Ÿæµ‹è¯• ===\n")
    
    analyzer = SimpleIntentAnalyzer()
    
    # æµ‹è¯•ç”¨ä¾‹é›†åˆ
    test_cases = [
        # ç»Ÿè®¡æŸ¥è¯¢æµ‹è¯•
        {
            "query": "ç»Ÿè®¡æµ™æ±Ÿçœæœ‰å¤šå°‘ä¸ª5Aæ™¯åŒº",
            "expected_intent": "summary",
            "expected_spatial": False,
            "description": "æ˜ç¡®ç»Ÿè®¡æŸ¥è¯¢"
        },
        {
            "query": "æŸ¥è¯¢æµ™æ±Ÿçœ5Aæ™¯åŒºçš„æ•°é‡",
            "expected_intent": "summary", 
            "expected_spatial": False,
            "description": "æ•°é‡æŸ¥è¯¢"
        },
        {
            "query": "æµ™æ±Ÿçœ4Aæ™¯åŒºæœ‰å¤šå°‘ä¸ª",
            "expected_intent": "summary",
            "expected_spatial": False,
            "description": "æœ‰å¤šå°‘ä¸ªæ¨¡å¼"
        },
        {
            "query": "ç»Ÿè®¡è¥¿æ¹–å‘¨å›´5å…¬é‡Œçš„æ™¯ç‚¹åˆ†å¸ƒ",
            "expected_intent": "summary",
            "expected_spatial": True,
            "description": "ç©ºé—´ç»Ÿè®¡æŸ¥è¯¢"
        },
        
        # ç©ºé—´æŸ¥è¯¢æµ‹è¯•
        {
            "query": "æŸ¥æ‰¾è·ç¦»æ­å·10å…¬é‡Œå†…çš„æ™¯ç‚¹",
            "expected_intent": "query",
            "expected_spatial": True,
            "description": "è·ç¦»æŸ¥è¯¢"
        },
        {
            "query": "æŸ¥è¯¢è¥¿æ¹–é™„è¿‘çš„æ™¯åŒº",
            "expected_intent": "query",
            "expected_spatial": True,
            "description": "é™„è¿‘æŸ¥è¯¢"
        },
        {
            "query": "æŸ¥æ‰¾æ­å·å¸‚å‘¨å›´çš„5Aæ™¯åŒº",
            "expected_intent": "query",
            "expected_spatial": True,
            "description": "å‘¨å›´æŸ¥è¯¢"
        },
        {
            "query": "æŸ¥è¯¢ç»çº¬åº¦120.15,30.28å‘¨å›´5å…¬é‡Œçš„æ™¯ç‚¹",
            "expected_intent": "query",
            "expected_spatial": True,
            "description": "åæ ‡è·ç¦»æŸ¥è¯¢"
        },
        
        # æ™®é€šæŸ¥è¯¢æµ‹è¯•
        {
            "query": "æŸ¥è¯¢æµ™æ±Ÿçœçš„5Aæ™¯åŒº",
            "expected_intent": "query",
            "expected_spatial": False,
            "description": "æ™®é€šæ™¯åŒºæŸ¥è¯¢"
        },
        {
            "query": "åˆ—å‡ºæ­å·å¸‚çš„æ‰€æœ‰æ™¯åŒº",
            "expected_intent": "query",
            "expected_spatial": False,
            "description": "åˆ—è¡¨æŸ¥è¯¢"
        },
        {
            "query": "æŸ¥æ‰¾è¥¿æ¹–çš„è¯¦ç»†ä¿¡æ¯",
            "expected_intent": "query",
            "expected_spatial": False,
            "description": "è¯¦æƒ…æŸ¥è¯¢"
        },
        
        # è¾¹ç•Œæƒ…å†µæµ‹è¯•
        {
            "query": "æµ™æ±Ÿçœæ™¯åŒº",
            "expected_intent": "query",
            "expected_spatial": False,
            "description": "ç®€å•æŸ¥è¯¢"
        },
        {
            "query": "æœ‰å¤šå°‘ä¸ª",
            "expected_intent": "summary",
            "expected_spatial": False,
            "description": "æ¨¡ç³Šç»Ÿè®¡æŸ¥è¯¢"
        },
        {
            "query": "é™„è¿‘æ™¯ç‚¹",
            "expected_intent": "query",
            "expected_spatial": True,
            "description": "æ¨¡ç³Šç©ºé—´æŸ¥è¯¢"
        }
    ]
    
    # è¿è¡Œæµ‹è¯•
    total_cases = len(test_cases)
    correct_intent = 0
    correct_spatial = 0
    
    print("æµ‹è¯•ç»“æœ:\n")
    print("=" * 120)
    print(f"{'æŸ¥è¯¢':<30} {'é¢„æœŸæ„å›¾':<12} {'å®é™…æ„å›¾':<12} {'æ„å›¾æ­£ç¡®':<8} {'é¢„æœŸç©ºé—´':<10} {'å®é™…ç©ºé—´':<10} {'ç©ºé—´æ­£ç¡®':<8} {'ç½®ä¿¡åº¦':<8} {'æè¿°':<20}")
    print("=" * 120)
    
    for test_case in test_cases:
        query = test_case["query"]
        expected_intent = test_case["expected_intent"]
        expected_spatial = test_case["expected_spatial"]
        
        # åˆ†ææ„å›¾
        result = analyzer.analyze_query_intent(query)
        
        actual_intent = result["intent_type"]
        actual_spatial = result["is_spatial"]
        confidence = result["confidence"]
        
        # æ£€æŸ¥æ­£ç¡®æ€§
        intent_correct = (actual_intent == expected_intent)
        spatial_correct = (actual_spatial == expected_spatial)
        
        if intent_correct:
            correct_intent += 1
        if spatial_correct:
            correct_spatial += 1
        
        # è¾“å‡ºç»“æœ
        print(f"{query:<30} {expected_intent:<12} {actual_intent:<12} {str(intent_correct):<8} {str(expected_spatial):<10} {str(actual_spatial):<10} {str(spatial_correct):<8} {confidence:.2f}     {test_case['description']:<20}")
        
        # å¦‚æœåˆ†æé”™è¯¯ï¼Œæ˜¾ç¤ºè¯¦ç»†åˆ†æä¿¡æ¯
        if not intent_correct or not spatial_correct:
            print(f"  âš ï¸ è¯¦ç»†åˆ†æ: {result['description']}")
            print(f"  ğŸ“Š åˆ†æè¯¦æƒ…: {result['analysis_details']}")
    
    print("=" * 120)
    
    # è®¡ç®—å‡†ç¡®ç‡
    intent_accuracy = correct_intent / total_cases * 100
    spatial_accuracy = correct_spatial / total_cases * 100
    overall_accuracy = (correct_intent + correct_spatial) / (total_cases * 2) * 100
    
    print(f"\næµ‹è¯•æ€»ç»“:")
    print(f"æ€»æµ‹è¯•ç”¨ä¾‹: {total_cases}")
    print(f"æ„å›¾åˆ†æå‡†ç¡®ç‡: {intent_accuracy:.1f}% ({correct_intent}/{total_cases})")
    print(f"ç©ºé—´åˆ†æå‡†ç¡®ç‡: {spatial_accuracy:.1f}% ({correct_spatial}/{total_cases})")
    print(f"æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.1f}%")
    
    # æ€§èƒ½è¯„ä¼°
    if overall_accuracy >= 90:
        print("âœ… æ„å›¾åˆ†æç³»ç»Ÿæ€§èƒ½ä¼˜ç§€ï¼")
    elif overall_accuracy >= 80:
        print("âœ… æ„å›¾åˆ†æç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼")
    elif overall_accuracy >= 70:
        print("âš ï¸ æ„å›¾åˆ†æç³»ç»Ÿæ€§èƒ½ä¸€èˆ¬ï¼Œéœ€è¦ä¼˜åŒ–")
    else:
        print("âŒ æ„å›¾åˆ†æç³»ç»Ÿæ€§èƒ½è¾ƒå·®ï¼Œéœ€è¦å¤§å¹…ä¼˜åŒ–")
    
    return overall_accuracy >= 80

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = test_intent_analysis()
    
    exit(0 if success else 1)
